{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd949f6f-d377-4c62-8e04-50c6b918dd52",
   "metadata": {},
   "source": [
    "# Quantum-Classical Hybrid Sequencer with EchoKey Integration\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Overview](#overview)\n",
    "2. [Features](#features)\n",
    "3. [EchoKey System Integration](#echokey-system-integration)\n",
    "    - [EchoKey Components](#echokey-components)\n",
    "    - [Synergy Measurements](#synergy-measurements)\n",
    "    - [Refraction Effect](#refraction-effect)\n",
    "4. [Architecture](#architecture)\n",
    "5. [Installation](#installation)\n",
    "6. [Usage](#usage)\n",
    "    - [Configuration](#configuration)\n",
    "    - [Running the Sequencer](#running-the-sequencer)\n",
    "7. [Project Structure](#project-structure)\n",
    "8. [Dependencies](#dependencies)\n",
    "9. [Results](#results)\n",
    "10. [Troubleshooting](#troubleshooting)\n",
    "11. [Contributing](#contributing)\n",
    "12. [License](#license)\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "Welcome to the **Quantum-Classical Hybrid Sequencer with EchoKey Integration**! This project combines the power of quantum computing with classical machine learning to create a sophisticated sequencer capable of predicting and extending multi-dimensional fractal sequences. The integration of the **EchoKey** system enhances the sequencer's performance by introducing entropy injection, synergy measurements, and refraction effects, enabling it to achieve high accuracy and robustness.\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Quantum Base-10 Encoding:** Utilizes a quantum system to encode base-10 digits (0-9) efficiently.\n",
    "- **Machine Learning Integration:** Employs Random Forest classifiers and LSTM neural networks to learn and predict sequence patterns.\n",
    "- **EchoKey System Integration:** Enhances the sequencer with cyclicity, fractality, entropy injection, and synergy measurements.\n",
    "- **Refraction Effects:** Applies refraction based on fractal layers and synergy parameters to adjust measurement probabilities.\n",
    "- **Synergy Measurements:** Calculates synergy parameters (`alpha`, `beta`, `gamma`) to inform refraction and enhance sequence prediction.\n",
    "- **Extensible and Configurable:** All critical parameters are configurable at the top of the script for easy customization.\n",
    "- **Visualization:** Plots predicted digits for the extended sequence to visualize performance.\n",
    "\n",
    "## EchoKey System Integration\n",
    "\n",
    "The **EchoKey** system is a novel framework designed to enhance computational models by introducing cyclicity, fractality, and entropy injection. In this sequencer, EchoKey components are integrated to improve prediction accuracy and system robustness.\n",
    "\n",
    "### EchoKey Components\n",
    "\n",
    "1. **RollingWindow:**\n",
    "    - **Purpose:** Manages a fixed-size rolling window to track recent state values.\n",
    "    - **Functionality:** \n",
    "        - Maintains a fixed-size buffer of recent mean probabilities.\n",
    "        - Provides neighbor values for synergy calculations.\n",
    "    - **Usage:** Used in calculating synergy parameters to inform refraction effects.\n",
    "\n",
    "2. **KeystreamScrambler:**\n",
    "    - **Purpose:** Injects entropy into measurement probabilities.\n",
    "    - **Functionality:**\n",
    "        - Generates a keystream based on a seed.\n",
    "        - Scrambles measurement probabilities to introduce randomness.\n",
    "    - **Usage:** Enhances the quantum state measurements by adding controlled randomness, improving robustness.\n",
    "\n",
    "### Synergy Measurements\n",
    "\n",
    "Synergy measurements are crucial for understanding the interdependencies within the system's states. The sequencer calculates synergy parameters (`alpha`, `beta`, `gamma`) using the `RollingWindow`:\n",
    "\n",
    "- **Alpha (`α`):** Mean of the neighboring state probabilities.\n",
    "- **Beta (`β`):** Standard deviation of the neighboring state probabilities.\n",
    "- **Gamma (`γ`):** Minimum of the neighboring state probabilities.\n",
    "\n",
    "These parameters are updated iteratively and used to calculate refractive indices, which adjust the measurement probabilities based on the system's current state.\n",
    "\n",
    "### Refraction Effect\n",
    "\n",
    "The refraction effect modifies the measurement probabilities to account for the fractal layer and synergy parameters:\n",
    "\n",
    "- **Refractive Index Calculation:**\n",
    "    \\[\n",
    "    \\text{refractive\\_index} = \\alpha + \\beta - \\gamma\n",
    "    \\]\n",
    "  \n",
    "- **Adjusted Probabilities:**\n",
    "    \\[\n",
    "    \\text{adjusted\\_probs} = \\text{probs} \\times \\left(1 + (\\text{layer} \\times \\text{refractive\\_coefficient} \\times \\text{refractive\\_index})\\right)\n",
    "    \\]\n",
    "  \n",
    "- **Normalization:** Ensures that the adjusted probabilities sum to 1.\n",
    "\n",
    "This mechanism allows the sequencer to dynamically adjust its probability distributions based on the fractal complexity and recent state interactions, enhancing prediction accuracy.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "The sequencer operates through an iterative process combining quantum state preparations, machine learning predictions, synergy measurements, and refraction effects. Here's a high-level overview of the workflow:\n",
    "\n",
    "1. **Data Initialization:**\n",
    "    - Read and process the target base-10 sequence from a CSV file.\n",
    "    - Assign fractal layers to each position in the sequence.\n",
    "\n",
    "2. **Quantum State Preparation:**\n",
    "    - Encode each digit into a quantum state using amplitude embedding and phase rotations.\n",
    "    - Inject entropy into the measurement probabilities via the `KeystreamScrambler`.\n",
    "\n",
    "3. **Synergy Calculations:**\n",
    "    - Use the `RollingWindow` to calculate synergy parameters (`alpha`, `beta`, `gamma`).\n",
    "\n",
    "4. **Refraction Application:**\n",
    "    - Adjust measurement probabilities based on fractal layers and synergy parameters.\n",
    "\n",
    "5. **Machine Learning Integration:**\n",
    "    - **Random Forest:** Trains on measurement probabilities and synergy parameters to classify digits.\n",
    "    - **LSTM:** Learns temporal patterns from sequences of measurement probabilities to predict future digits.\n",
    "\n",
    "6. **Prediction and Extension:**\n",
    "    - Once the initial sequence is matched, the system predicts additional digits to extend the sequence.\n",
    "\n",
    "7. **Data Logging and Visualization:**\n",
    "    - Logs all relevant data into CSV files.\n",
    "    - Visualizes predicted digits for analysis.\n",
    "\n",
    "## Installation\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Ensure you have the following installed on your system:\n",
    "\n",
    "- **Python 3.7 or higher**\n",
    "\n",
    "### Clone the Repository\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/yourusername/quantum-classical-hybrid-sequencer.git\n",
    "cd quantum-classical-hybrid-sequencer\n",
    "```\n",
    "\n",
    "### Create a Virtual Environment (Optional but Recommended)\n",
    "\n",
    "```bash\n",
    "python -m venv venv\n",
    "source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "### Install Dependencies\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "**Note:** If `requirements.txt` is not provided, install the necessary packages manually:\n",
    "\n",
    "```bash\n",
    "pip install numpy pandas pennylane scikit-learn tensorflow matplotlib\n",
    "```\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Configuration\n",
    "\n",
    "All critical parameters are defined at the top of the script for easy modification. Adjust them as needed:\n",
    "\n",
    "```python\n",
    "# Data parameters\n",
    "CSV_FILE = 'recaman_puzzle.csv'        # CSV file containing the target sequence\n",
    "COLUMN_NAME = 'Puzzle'                 # Column name in the CSV file\n",
    "\n",
    "# Quantum parameters\n",
    "NUM_QUBITS = 4                         # Number of qubits (should be at least 4 for base-10)\n",
    "BASE_DIMENSION = 10                    # Base dimension (for base-10 digits 0-9)\n",
    "\n",
    "# EchoKey parameters\n",
    "ECHOKEY_SEED = np.random.randint(0, 1e6)\n",
    "ROLLING_WINDOW_SIZE = 8                # Size of the rolling window for synergy calculations\n",
    "\n",
    "# Fractal parameters\n",
    "MAX_LAYERS = 10                        # Maximum number of fractal layers\n",
    "FRACTAL_REGRESSIVE_COEFF = 0.95        # Fixed regressive coefficient upon successful match\n",
    "\n",
    "# Machine Learning parameters\n",
    "TIME_STEPS = 5                         # Number of time steps for LSTM input sequence\n",
    "LSTM_UNITS = 64                        # Number of units in the LSTM layer\n",
    "RF_N_ESTIMATORS = 100                  # Number of trees in the Random Forest\n",
    "RF_MAX_DEPTH = 10                      # Maximum depth of the Random Forest trees\n",
    "\n",
    "# Simulation parameters\n",
    "NUM_RUNS = 1                           # Number of independent runs (set to 1 for testing)\n",
    "MAX_ITERATIONS = 1000                  # Maximum iterations per run\n",
    "LEARNING_RATE = 0.05                   # Learning rate (not directly used here)\n",
    "PREDICT_NEXT = 100                     # Number of positions to predict after matching\n",
    "\n",
    "# Output parameters\n",
    "OUTPUT_DIR = \"simulation_results\"      # Directory to save simulation results\n",
    "```\n",
    "\n",
    "### Running the Sequencer\n",
    "\n",
    "Ensure your target CSV file (e.g., `recaman_puzzle.csv`) is placed in the working directory with the correct column name (`Puzzle`).\n",
    "\n",
    "Execute the script:\n",
    "\n",
    "```bash\n",
    "python sequencer.py\n",
    "```\n",
    "\n",
    "**Note:** Replace `sequencer.py` with the actual filename if different.\n",
    "\n",
    "### Output\n",
    "\n",
    "- **CSV Files:** Detailed logs of each run are saved in the `simulation_results` directory with timestamps.\n",
    "- **Plots:** After convergence, plots of predicted digits for the extended sequence are displayed for analysis.\n",
    "\n",
    "## Project Structure\n",
    "\n",
    "```\n",
    "quantum-classical-hybrid-sequencer/\n",
    "│\n",
    "├── sequencer.py                  # Main script integrating EchoKey\n",
    "├── recaman_puzzle.csv            # Sample target sequence CSV file\n",
    "├── simulation_results/           # Directory to save results\n",
    "│   ├── Run_1_Data_YYYYMMDD_HHMMSS.csv\n",
    "│   └── Run_1_Extended_Data_YYYYMMDD_HHMMSS.csv\n",
    "├── requirements.txt              # Python dependencies\n",
    "└── README.md                     # Project documentation\n",
    "```\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- **Python Libraries:**\n",
    "    - `numpy`\n",
    "    - `pandas`\n",
    "    - `pennylane`\n",
    "    - `scikit-learn`\n",
    "    - `tensorflow`\n",
    "    - `matplotlib`\n",
    "    - `psutil` (optional, used for system monitoring)\n",
    "  \n",
    "- **Quantum Backend:**\n",
    "    - `PennyLane` uses `default.qubit` for simulations. For real quantum hardware, additional setup is required.\n",
    "\n",
    "## Results\n",
    "\n",
    "After successfully running the sequencer, you'll observe output indicating the progress of matches and the final predictions. A successful run will display:\n",
    "\n",
    "```\n",
    "Total Matches: 674/674 (100.00%) nailed it, thanks dude\n",
    "```\n",
    "\n",
    "Additionally, detailed CSV logs and visual plots will help you analyze the performance and accuracy of the sequencer.\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "- **Syntax Errors:**\n",
    "    - Ensure that all global variables are declared correctly.\n",
    "    - Verify the placement of `global` statements before variable usage.\n",
    "\n",
    "- **CSV File Issues:**\n",
    "    - Confirm that the CSV file exists in the working directory.\n",
    "    - Ensure the specified column (`Puzzle`) contains only integer digits (0-9).\n",
    "\n",
    "- **Dependencies:**\n",
    "    - If you encounter import errors, ensure all dependencies are installed correctly.\n",
    "    - Use a virtual environment to manage dependencies effectively.\n",
    "\n",
    "- **Quantum Simulation Errors:**\n",
    "    - Check if the number of qubits (`NUM_QUBITS`) is sufficient for base-10 encoding.\n",
    "    - Ensure that `BASE_DIMENSION` is set to 10 for digits 0-9.\n",
    "\n",
    "## Contributing\n",
    "\n",
    "Contributions are welcome! If you'd like to enhance the sequencer, fix bugs, or add new features, please follow these steps:\n",
    "\n",
    "1. **Fork the Repository**\n",
    "2. **Create a New Branch**\n",
    "    ```bash\n",
    "    git checkout -b feature/YourFeature\n",
    "    ```\n",
    "3. **Commit Your Changes**\n",
    "    ```bash\n",
    "    git commit -m \"Add your feature\"\n",
    "    ```\n",
    "4. **Push to the Branch**\n",
    "    ```bash\n",
    "    git push origin feature/YourFeature\n",
    "    ```\n",
    "5. **Open a Pull Request**\n",
    "\n",
    "Please ensure that your contributions adhere to the project's coding standards and include appropriate documentation.\n",
    "\n",
    "## License\n",
    "\n",
    "This project is licensed under the [MIT License](LICENSE).\n",
    "\n",
    "---\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "- **PennyLane:** For providing a powerful framework for quantum machine learning.\n",
    "- **Scikit-Learn & TensorFlow:** For robust machine learning tools.\n",
    "- **EchoKey Framework:** For inspiring entropy injection and synergy measurement integration.\n",
    "\n",
    "---\n",
    "\n",
    "Feel free to reach out if you have any questions or need further assistance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb0157-a795-4996-b8aa-34f2e8efb5f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Combined Quantum-Classical Hybrid System with Machine Learning and Synergy Measurements\n",
    "# Enhanced with EchoKey Integration\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import psutil\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp  # Use PennyLane's NumPy for compatibility\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "# Suppress warnings for cleaner output (optional)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =============================================================================\n",
    "# EchoKey Components\n",
    "# =============================================================================\n",
    "\n",
    "# RollingWindow class for managing state\n",
    "class RollingWindow:\n",
    "    \"\"\"Efficient rolling window using a fixed size.\"\"\"\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.data = np.zeros(size)\n",
    "        self.index = 0\n",
    "\n",
    "    def update(self, value):\n",
    "        self.data[self.index % self.size] = value\n",
    "        self.index += 1\n",
    "\n",
    "    def get_neighbors(self, n_neighbors=8):\n",
    "        if n_neighbors > self.size:\n",
    "            n_neighbors = self.size\n",
    "        start = (self.index - n_neighbors) % self.size\n",
    "        if start + n_neighbors <= self.size:\n",
    "            return self.data[start:start + n_neighbors]\n",
    "        else:\n",
    "            end = (start + n_neighbors) % self.size\n",
    "            return np.concatenate((self.data[start:], self.data[:end]))\n",
    "\n",
    "# KeystreamScrambler class from EchoKey for entropy injection\n",
    "class KeystreamScrambler:\n",
    "    \"\"\"Generates and uses a keystream for scrambling and injecting entropy.\"\"\"\n",
    "    def __init__(self, seed):\n",
    "        self.seed = seed\n",
    "        self.counter = 0\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    def generate_keystream(self, length):\n",
    "        keystream = np.random.randint(1, 256, size=length, dtype=np.uint8)\n",
    "        return keystream\n",
    "\n",
    "# =============================================================================\n",
    "# Quantum Base-10 Controller Class with EchoKey Integration\n",
    "# =============================================================================\n",
    "\n",
    "class QuantumBase10Controller:\n",
    "    def __init__(self, num_qubits=4, seed=None):\n",
    "        self.num_qubits = num_qubits\n",
    "        self.device = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "        self.d = 2 ** num_qubits  # Dimension of the system (should be at least 10 for base-10)\n",
    "        self.scrambler = KeystreamScrambler(seed=seed or np.random.randint(0, 1e6))\n",
    "\n",
    "    def base10_model(self, digit: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Prepares a quantum state corresponding to the given base-10 digit,\n",
    "        integrates EchoKey's cyclic and fractal components, and injects entropy.\n",
    "\n",
    "        Parameters:\n",
    "        - digit (int): The base-10 digit to encode (0-9).\n",
    "\n",
    "        Returns:\n",
    "        - adjusted_probs (np.ndarray): Measurement probabilities adjusted with entropy injection.\n",
    "        \"\"\"\n",
    "        @qml.qnode(self.device)\n",
    "        def circuit():\n",
    "            # Initialize the quantum state corresponding to the digit using amplitude encoding\n",
    "            state = np.zeros(self.d)\n",
    "            state[digit] = 1.0  # Set amplitude for the target digit\n",
    "            qml.AmplitudeEmbedding(state, wires=range(self.num_qubits), normalize=True)\n",
    "            # Apply EchoKey cyclic phase encoding\n",
    "            for n in range(self.num_qubits):\n",
    "                angle = 2 * np.pi * digit / (2 ** n)\n",
    "                qml.RZ(angle, wires=n)\n",
    "            return qml.probs(wires=range(self.num_qubits))\n",
    "\n",
    "        # Execute the quantum node\n",
    "        probs = circuit()\n",
    "\n",
    "        # Inject entropy into measurement probabilities using the scrambler\n",
    "        entropy = self.scrambler.generate_keystream(len(probs))\n",
    "        entropy = entropy / 255.0  # Normalize to [0, 1]\n",
    "        adjusted_probs = probs * entropy\n",
    "\n",
    "        # Normalize probabilities\n",
    "        adjusted_probs /= np.sum(adjusted_probs)\n",
    "\n",
    "        return adjusted_probs\n",
    "\n",
    "# =============================================================================\n",
    "# Data Reading and Processing Functions\n",
    "# =============================================================================\n",
    "\n",
    "def read_target_sequence(csv_file='recaman_puzzle.csv', column_name='Puzzle'):\n",
    "    \"\"\"\n",
    "    Reads the target base-10 sequence from a CSV file and converts it into a list of integers.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_file (str): Path to the CSV file.\n",
    "    - column_name (str): Name of the column containing the puzzle sequence.\n",
    "\n",
    "    Returns:\n",
    "    - target_sequence (list): List of integers representing the target sequence.\n",
    "    \"\"\"\n",
    "    print(\"Reading and processing the data...\")\n",
    "    try:\n",
    "        puzzle_df = pd.read_csv(csv_file)\n",
    "        print(\"Data read from CSV:\")\n",
    "        print(puzzle_df.head())\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: '{csv_file}' not found. Please ensure the file exists in the working directory.\")\n",
    "        sys.exit(1)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: '{csv_file}' is empty.\")\n",
    "        sys.exit(1)\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Error: '{csv_file}' is malformed.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    if column_name not in puzzle_df.columns:\n",
    "        print(f\"Error: Column '{column_name}' not found in '{csv_file}'.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Combine all rows in the specified column into a single string\n",
    "    target_str = puzzle_df[column_name].astype(str).str.cat()\n",
    "    \n",
    "    # Convert the string into a list of integers\n",
    "    try:\n",
    "        target_sequence = [int(char) for char in target_str if char.isdigit()]\n",
    "    except ValueError:\n",
    "        print(f\"Error: Non-integer values found in the '{column_name}' column.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Ensure digits are between 0 and 9\n",
    "    target_sequence = [digit for digit in target_sequence if 0 <= digit <= 9]\n",
    "    \n",
    "    print(f\"Target sequence length: {len(target_sequence)}\")\n",
    "    print(f\"Target sequence: {target_sequence}\")\n",
    "    return target_sequence\n",
    "\n",
    "# =============================================================================\n",
    "# Assign Fractal Layers to Sequence Positions\n",
    "# =============================================================================\n",
    "\n",
    "def assign_fractal_layers(sequence_length, max_layers):\n",
    "    \"\"\"\n",
    "    Assigns fractal layers to each position in the sequence.\n",
    "\n",
    "    Parameters:\n",
    "    - sequence_length (int): The length of the target sequence.\n",
    "    - max_layers (int): Maximum number of fractal layers.\n",
    "\n",
    "    Returns:\n",
    "    - fractal_layers (list): List indicating the fractal layer assigned to each position.\n",
    "    \"\"\"\n",
    "    fractal_layers = [0] * sequence_length\n",
    "    layer = 1\n",
    "    step = 1\n",
    "    while layer <= max_layers and step < sequence_length:\n",
    "        for i in range(0, sequence_length, step * 2):\n",
    "            if i + step < sequence_length:\n",
    "                fractal_layers[i + step] = layer\n",
    "        layer += 1\n",
    "        step *= 2\n",
    "    return fractal_layers\n",
    "\n",
    "# =============================================================================\n",
    "# Synergy Measurements Functions with EchoKey Integration\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_synergy_parameters(probs, rolling_window: RollingWindow) -> dict:\n",
    "    \"\"\"\n",
    "    Calculates synergy parameters using EchoKey's rolling windows.\n",
    "\n",
    "    Parameters:\n",
    "    - probs (np.ndarray): Measurement probabilities.\n",
    "    - rolling_window (RollingWindow): Rolling window for synergy calculations.\n",
    "\n",
    "    Returns:\n",
    "    - synergy_params (dict): Dictionary containing 'alpha', 'beta', and 'gamma'.\n",
    "    \"\"\"\n",
    "    # Update the rolling window with the mean probability\n",
    "    rolling_window.update(np.mean(probs))\n",
    "\n",
    "    # Get the neighbors from the rolling window\n",
    "    neighbors = rolling_window.get_neighbors(n_neighbors=8)\n",
    "\n",
    "    # Calculate synergy parameters as per the EchoKey unified equation\n",
    "    alpha = np.mean(neighbors)\n",
    "    beta = np.std(neighbors)\n",
    "    gamma = np.min(neighbors)\n",
    "\n",
    "    synergy_params = {\n",
    "        'alpha': alpha,\n",
    "        'beta': beta,\n",
    "        'gamma': gamma\n",
    "    }\n",
    "\n",
    "    return synergy_params\n",
    "\n",
    "# =============================================================================\n",
    "# Refraction Effect Function using EchoKey's Unified Equation\n",
    "# =============================================================================\n",
    "\n",
    "def apply_refractive_effect(layer, probs, refractive_coefficient=0.1, synergy_params=None):\n",
    "    \"\"\"\n",
    "    Applies a refractive effect to the measurement probabilities based on the fractal layer\n",
    "    and EchoKey's synergy parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - layer (int): The fractal layer number.\n",
    "    - probs (np.ndarray): Original measurement probabilities.\n",
    "    - refractive_coefficient (float): Coefficient to determine the strength of refraction.\n",
    "    - synergy_params (dict): Synergy parameters from EchoKey framework.\n",
    "\n",
    "    Returns:\n",
    "    - adjusted_probs (np.ndarray): Refraction-adjusted measurement probabilities.\n",
    "    \"\"\"\n",
    "    if layer == 0 or synergy_params is None:\n",
    "        return probs  # No refraction for layer 0 or missing synergy parameters\n",
    "\n",
    "    # Calculate refractive index using EchoKey's unified equation components\n",
    "    refractive_index = synergy_params['alpha'] + synergy_params['beta'] - synergy_params['gamma']\n",
    "    refractive_effect = 1 + (layer * refractive_coefficient * refractive_index)\n",
    "\n",
    "    adjusted_probs = probs * refractive_effect\n",
    "    # Re-normalize to ensure probabilities sum to 1\n",
    "    adjusted_probs /= np.sum(adjusted_probs)\n",
    "    return adjusted_probs\n",
    "\n",
    "# =============================================================================\n",
    "# Initialize the Random Forest Classifier and LSTM Model\n",
    "# =============================================================================\n",
    "\n",
    "def initialize_random_forest(n_estimators=100, max_depth=10):\n",
    "    \"\"\"\n",
    "    Initializes the Random Forest classifier for the classical search component.\n",
    "\n",
    "    Parameters:\n",
    "    - n_estimators (int): Number of trees in the forest.\n",
    "    - max_depth (int): Maximum depth of the tree.\n",
    "\n",
    "    Returns:\n",
    "    - rf_classifier (RandomForestClassifier): Initialized Random Forest classifier.\n",
    "    \"\"\"\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "    print(\"Random Forest classifier initialized.\")\n",
    "    return rf_classifier\n",
    "\n",
    "def initialize_lstm(input_shape, output_dim):\n",
    "    \"\"\"\n",
    "    Initializes the LSTM model for handling time steps.\n",
    "\n",
    "    Parameters:\n",
    "    - input_shape (tuple): Shape of the input data (timesteps, features).\n",
    "    - output_dim (int): Output dimension equal to number of base-10 digits.\n",
    "\n",
    "    Returns:\n",
    "    - model (Sequential): Compiled LSTM model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=input_shape, return_sequences=False))\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(\"LSTM model initialized and compiled.\")\n",
    "    return model\n",
    "\n",
    "# =============================================================================\n",
    "# Evolve the Quantum-Classical Hybrid System with EchoKey Integration\n",
    "# =============================================================================\n",
    "\n",
    "def evolve_system(target_sequence, quantum_controller, num_qubits, rf_classifier, lstm_model,\n",
    "                  fractal_layers, rolling_window, num_runs=10, max_iterations=1000, learning_rate=0.05,\n",
    "                  fractal_regressive_coeff=0.95, time_steps=5, predict_next=100):\n",
    "    \"\"\"\n",
    "    Evolve the quantum-classical hybrid system using the QuantumBase10Controller,\n",
    "    Random Forest, LSTM, Fractal Layers, EchoKey Synergy Measurements, and Refraction Effects.\n",
    "\n",
    "    Parameters:\n",
    "    - target_sequence (list): The target base-10 sequence to predict.\n",
    "    - quantum_controller (QuantumBase10Controller): Quantum controller instance.\n",
    "    - num_qubits (int): Number of qubits in the quantum system.\n",
    "    - rf_classifier (RandomForestClassifier): Initialized Random Forest classifier.\n",
    "    - lstm_model (Sequential): Initialized LSTM model.\n",
    "    - fractal_layers (list): List indicating fractal layers for each sequence position.\n",
    "    - rolling_window (RollingWindow): Rolling window for synergy calculations.\n",
    "    - num_runs (int): Number of independent runs.\n",
    "    - max_iterations (int): Maximum iterations per run.\n",
    "    - learning_rate (float): Learning rate (not directly used here).\n",
    "    - fractal_regressive_coeff (float): Fixed regressive coefficient upon successful match.\n",
    "    - time_steps (int): Number of time steps for LSTM input sequence.\n",
    "    - predict_next (int): Number of positions to predict after matching.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    print(\"Evolving the system iteratively with EchoKey integration...\")\n",
    "\n",
    "    # Directory to save CSV files\n",
    "    output_dir = \"simulation_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    d = 2 ** num_qubits  # Dimension of the system\n",
    "\n",
    "    for run in range(1, num_runs + 1):\n",
    "        print(f\"\\n--- Run {run} ---\")\n",
    "        iteration = 0\n",
    "        converged = False\n",
    "\n",
    "        # Initialize data storage for this run\n",
    "        run_data = []\n",
    "\n",
    "        # Initialize a set to track matched positions\n",
    "        matched_positions = set()\n",
    "\n",
    "        # Initialize sequence data for LSTM\n",
    "        lstm_sequence_data = []\n",
    "        lstm_target_data = []\n",
    "\n",
    "        # Total positions (initial target sequence length)\n",
    "        total_positions = len(target_sequence)\n",
    "\n",
    "        while not converged and iteration < max_iterations:\n",
    "            iteration += 1\n",
    "            print(f\"\\nIteration {iteration}\")\n",
    "\n",
    "            # Iterate over the target sequence\n",
    "            for idx, target_digit in enumerate(target_sequence):\n",
    "                # Skip if position's fractal layer is higher than current iteration\n",
    "                if fractal_layers[idx] > iteration:\n",
    "                    continue\n",
    "\n",
    "                # Generate the quantum probabilities using the QuantumBase10Controller\n",
    "                probs = quantum_controller.base10_model(target_digit)\n",
    "\n",
    "                # Calculate synergy parameters using EchoKey's rolling window\n",
    "                synergy_params = calculate_synergy_parameters(probs, rolling_window)\n",
    "\n",
    "                # Apply refraction effect based on fractal layer and synergy parameters\n",
    "                probs = apply_refractive_effect(fractal_layers[idx], probs, synergy_params=synergy_params)\n",
    "\n",
    "                # Measured state is the one with the highest probability\n",
    "                measured_state = np.argmax(probs)\n",
    "                target_state = target_digit  # Since the target is a digit (0-9)\n",
    "\n",
    "                # Collect data for Random Forest and LSTM\n",
    "                position_data = {\n",
    "                    'Run': run,\n",
    "                    'Iteration': iteration,\n",
    "                    'Position': idx,\n",
    "                    'Target_Digit': target_digit,\n",
    "                    'Measured_State': measured_state,\n",
    "                    'Fractal_Layer': fractal_layers[idx],\n",
    "                    'Predicted_Digit': np.nan,  # Set to NaN during initial matching,\n",
    "                    'Alpha': synergy_params['alpha'],\n",
    "                    'Beta': synergy_params['beta'],\n",
    "                    'Gamma': synergy_params['gamma']\n",
    "                }\n",
    "                # Add measurement probabilities as separate columns\n",
    "                for state_idx, prob in enumerate(probs):\n",
    "                    position_data[f'Prob_State_{state_idx}'] = prob\n",
    "\n",
    "                run_data.append(position_data)\n",
    "\n",
    "                # Prepare data for LSTM (sequence of measurement probabilities)\n",
    "                lstm_sequence_data.append(probs)\n",
    "                lstm_target_data.append(target_state)\n",
    "\n",
    "                # Check if measured state matches target state\n",
    "                if measured_state == target_state:\n",
    "                    matched_positions.add(idx)\n",
    "                    print(f\"Matched state at position {idx}: {measured_state}\")\n",
    "                else:\n",
    "                    print(f\"Mismatch at position {idx}: Measured {measured_state} != Target {target_state}\")\n",
    "\n",
    "            # Print progress update\n",
    "            matched_count = len(matched_positions)\n",
    "            print(f\"\\nProgress Update: {matched_count} out of {total_positions} positions have been matched.\")\n",
    "\n",
    "            # Check for convergence\n",
    "            if matched_count == total_positions:\n",
    "                print(f\"All positions have been assigned and matched in run {run} after {iteration} iterations!\")\n",
    "                converged = True\n",
    "                # Save the data to CSV\n",
    "                df_run = pd.DataFrame(run_data)\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                csv_filename = f\"Run_{run}_Data_{timestamp}.csv\"\n",
    "                csv_path = os.path.join(output_dir, csv_filename)\n",
    "                df_run.to_csv(csv_path, index=False)\n",
    "                print(f\"Data for run {run} saved to '{csv_path}'.\")\n",
    "                # Continue to predict next positions\n",
    "                break  # Exit the iteration loop to proceed to prediction\n",
    "\n",
    "            # Train the Random Forest classifier with accumulated data\n",
    "            if run_data:\n",
    "                # Prepare data for training\n",
    "                df_run = pd.DataFrame(run_data)\n",
    "                feature_columns = [f'Prob_State_{i}' for i in range(d)] + ['Alpha', 'Beta', 'Gamma']\n",
    "\n",
    "                # Create 'Digit_Label' column\n",
    "                df_run['Digit_Label'] = df_run['Target_Digit']\n",
    "\n",
    "                X_train_rf = df_run[feature_columns]\n",
    "                y_train_rf = df_run['Digit_Label']\n",
    "\n",
    "                rf_classifier.fit(X_train_rf, y_train_rf)\n",
    "                print(\"Random Forest classifier trained with current data.\")\n",
    "\n",
    "            # Train the LSTM model with accumulated sequence data\n",
    "            if len(lstm_sequence_data) >= time_steps:\n",
    "                X_train_lstm = []\n",
    "                y_train_lstm = []\n",
    "                for i in range(len(lstm_sequence_data) - time_steps):\n",
    "                    X_train_lstm.append(lstm_sequence_data[i:i+time_steps])\n",
    "                    y_train_lstm.append(lstm_target_data[i+time_steps])\n",
    "                X_train_lstm = np.array(X_train_lstm)\n",
    "                y_train_lstm = np.array(y_train_lstm)\n",
    "                y_train_lstm = pd.get_dummies(y_train_lstm).values  # One-hot encoding\n",
    "\n",
    "                lstm_model.fit(X_train_lstm, y_train_lstm, epochs=1, batch_size=32, verbose=0)\n",
    "                print(\"LSTM model trained with current sequence data.\")\n",
    "\n",
    "                # Use LSTM to predict and adjust future iterations\n",
    "                latest_sequence = np.array(lstm_sequence_data[-time_steps:]).reshape(1, time_steps, d)\n",
    "                lstm_prediction = lstm_model.predict(latest_sequence)\n",
    "                predicted_state_lstm = np.argmax(lstm_prediction, axis=1)[0]\n",
    "                print(f\"LSTM Prediction for next state: {predicted_state_lstm}\")\n",
    "\n",
    "            # Use Random Forest to predict and adjust future iterations\n",
    "            if run_data:\n",
    "                latest_data = run_data[-1]\n",
    "                latest_features = np.array([latest_data[f'Prob_State_{i}'] for i in range(d)] + [\n",
    "                    latest_data['Alpha'],\n",
    "                    latest_data['Beta'],\n",
    "                    latest_data['Gamma']\n",
    "                ]).reshape(1, -1)\n",
    "                predicted_state_rf = rf_classifier.predict(latest_features)[0]\n",
    "                print(f\"Random Forest Prediction for next state: {predicted_state_rf}\")\n",
    "\n",
    "        # After matching the initial sequence, predict the next positions\n",
    "        if converged:\n",
    "            print(f\"\\nProceeding to predict the next {predict_next} positions in the sequence...\")\n",
    "            predicted_positions = []\n",
    "            for idx in range(total_positions, total_positions + predict_next):\n",
    "                # Prepare the input for LSTM\n",
    "                if len(lstm_sequence_data) >= time_steps:\n",
    "                    input_sequence = np.array(lstm_sequence_data[-time_steps:]).reshape(1, time_steps, d)\n",
    "                    lstm_prediction = lstm_model.predict(input_sequence)\n",
    "                    predicted_digit = np.argmax(lstm_prediction, axis=1)[0]\n",
    "                else:\n",
    "                    # If not enough data, default to a random digit\n",
    "                    predicted_digit = np.random.randint(0, 10)\n",
    "\n",
    "                # Generate the quantum probabilities using the predicted digit\n",
    "                probs = quantum_controller.base10_model(predicted_digit)\n",
    "\n",
    "                # Calculate synergy parameters\n",
    "                synergy_params = calculate_synergy_parameters(probs, rolling_window)\n",
    "\n",
    "                # Apply refraction effect based on fractal layer (assuming 'Prediction' layer)\n",
    "                prediction_layer = max(fractal_layers) + 1\n",
    "                probs = apply_refractive_effect(prediction_layer, probs, synergy_params=synergy_params)\n",
    "\n",
    "                # Measured state is the one with the highest probability\n",
    "                measured_state = np.argmax(probs)\n",
    "\n",
    "                # Collect data\n",
    "                position_data = {\n",
    "                    'Run': run,\n",
    "                    'Iteration': iteration + (idx - total_positions + 1),  # Continue iteration count\n",
    "                    'Position': idx,\n",
    "                    'Predicted_Digit': predicted_digit,\n",
    "                    'Measured_State': measured_state,\n",
    "                    'Fractal_Layer': 'Prediction',\n",
    "                    'Target_Digit': np.nan,  # No target digit during prediction\n",
    "                    'Alpha': synergy_params['alpha'],\n",
    "                    'Beta': synergy_params['beta'],\n",
    "                    'Gamma': synergy_params['gamma']\n",
    "                }\n",
    "                # Add measurement probabilities as separate columns\n",
    "                for state_idx, prob in enumerate(probs):\n",
    "                    position_data[f'Prob_State_{state_idx}'] = prob\n",
    "\n",
    "                run_data.append(position_data)\n",
    "                lstm_sequence_data.append(probs)\n",
    "                lstm_target_data.append(predicted_digit)\n",
    "                predicted_positions.append(predicted_digit)\n",
    "\n",
    "                print(f\"Predicted digit at position {idx}: {predicted_digit}\")\n",
    "\n",
    "                # Retrain the Random Forest classifier\n",
    "                df_run = pd.DataFrame(run_data)\n",
    "                feature_columns = [f'Prob_State_{i}' for i in range(d)] + ['Alpha', 'Beta', 'Gamma']\n",
    "\n",
    "                # Create 'Digit_Label' column that combines 'Predicted_Digit' and 'Target_Digit'\n",
    "                df_run['Digit_Label'] = df_run['Predicted_Digit'].combine_first(df_run['Target_Digit'])\n",
    "\n",
    "                # Drop rows where 'Digit_Label' is NaN\n",
    "                df_run_rf = df_run[df_run['Digit_Label'].notna()]\n",
    "\n",
    "                X_train_rf = df_run_rf[feature_columns]\n",
    "                y_train_rf = df_run_rf['Digit_Label']\n",
    "\n",
    "                rf_classifier.fit(X_train_rf, y_train_rf)\n",
    "                print(\"Random Forest classifier retrained with latest data.\")\n",
    "\n",
    "                # Retrain the LSTM model\n",
    "                if len(lstm_sequence_data) >= time_steps:\n",
    "                    X_train_lstm = []\n",
    "                    y_train_lstm = []\n",
    "                    for i in range(len(lstm_sequence_data) - time_steps):\n",
    "                        X_train_lstm.append(lstm_sequence_data[i:i+time_steps])\n",
    "                        y_train_lstm.append(lstm_target_data[i+time_steps])\n",
    "                    X_train_lstm = np.array(X_train_lstm)\n",
    "                    y_train_lstm = np.array(y_train_lstm)\n",
    "                    y_train_lstm = pd.get_dummies(y_train_lstm).values  # One-hot encoding\n",
    "\n",
    "                    lstm_model.fit(X_train_lstm, y_train_lstm, epochs=1, batch_size=32, verbose=0)\n",
    "                    print(\"LSTM model retrained with latest sequence data.\")\n",
    "\n",
    "            # Save the extended data to CSV\n",
    "            df_run = pd.DataFrame(run_data)\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            csv_filename = f\"Run_{run}_Extended_Data_{timestamp}.csv\"\n",
    "            csv_path = os.path.join(output_dir, csv_filename)\n",
    "            df_run.to_csv(csv_path, index=False)\n",
    "            print(f\"Extended data for run {run} saved to '{csv_path}'.\")\n",
    "\n",
    "            # Plot the predicted digits\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(range(total_positions, total_positions + predict_next), predicted_positions, label='Predicted Digits', marker='o', markersize=4, linewidth=1)\n",
    "            plt.xlabel('Position in Sequence')\n",
    "            plt.ylabel('Predicted Digit')\n",
    "            plt.title(f'Predicted Digits for Next {predict_next} Positions - Run {run}')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            print(f\"Run {run} did not fully converge after {max_iterations} iterations.\")\n",
    "            if run_data:\n",
    "                df_run = pd.DataFrame(run_data)\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                csv_filename = f\"Run_{run}_Data_{timestamp}.csv\"\n",
    "                csv_path = os.path.join(output_dir, csv_filename)\n",
    "                df_run.to_csv(csv_path, index=False)\n",
    "                print(f\"Partial data for run {run} saved to '{csv_path}'.\")\n",
    "\n",
    "# =============================================================================\n",
    "# Main Execution\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    # Define parameters\n",
    "    csv_file = 'recaman_puzzle.csv'               # CSV file containing the target sequence\n",
    "    column_name = 'Puzzle'                         # Column name in the CSV file\n",
    "    num_qubits = 4                                 # Number of qubits (should be at least 4 for base-10)\n",
    "    num_runs = 1                                   # Number of independent runs (set to 1 for testing)\n",
    "    max_iterations = 1000                          # Maximum iterations per run\n",
    "    learning_rate = 0.05                           # Learning rate (not directly used here)\n",
    "    fractal_regressive_coeff = 0.95                # Fixed regressive coefficient upon successful match\n",
    "    max_layers = 10                                # Maximum number of fractal layers\n",
    "    time_steps = 5                                 # Number of time steps for LSTM input sequence\n",
    "    predict_next = 100                             # Number of positions to predict after matching\n",
    "\n",
    "    # Step 1: Read the target sequence\n",
    "    target_sequence = read_target_sequence(csv_file, column_name)\n",
    "\n",
    "    # Ensure that the number of qubits is sufficient for base-10 encoding\n",
    "    d = 2 ** num_qubits\n",
    "    if d < 10:\n",
    "        num_qubits = int(np.ceil(np.log2(10)))\n",
    "        print(f\"Adjusted number of qubits to {num_qubits} to accommodate base-10 digits.\")\n",
    "        d = 2 ** num_qubits\n",
    "\n",
    "    # Step 2: Initialize the QuantumBase10Controller with EchoKey seed\n",
    "    echokey_seed = np.random.randint(0, 1e6)\n",
    "    quantum_controller = QuantumBase10Controller(num_qubits=num_qubits, seed=echokey_seed)\n",
    "\n",
    "    # Step 3: Initialize the Random Forest classifier\n",
    "    rf_classifier = initialize_random_forest()\n",
    "\n",
    "    # Step 4: Initialize the LSTM model\n",
    "    lstm_input_shape = (time_steps, d)  # (timesteps, features)\n",
    "    lstm_output_dim = 10                # Output dimension equal to number of base-10 digits\n",
    "    lstm_model = initialize_lstm(lstm_input_shape, lstm_output_dim)\n",
    "\n",
    "    # Step 5: Assign fractal layers to sequence positions\n",
    "    fractal_layers = assign_fractal_layers(len(target_sequence), max_layers)\n",
    "    print(\"Fractal layers assigned to sequence positions.\")\n",
    "\n",
    "    # Step 6: Initialize EchoKey Rolling Window\n",
    "    rolling_window_size = 8\n",
    "    rolling_window = RollingWindow(size=rolling_window_size)\n",
    "\n",
    "    # Step 7: Evolve the system with EchoKey integration\n",
    "    evolve_system(\n",
    "        target_sequence=target_sequence,\n",
    "        quantum_controller=quantum_controller,\n",
    "        num_qubits=num_qubits,\n",
    "        rf_classifier=rf_classifier,\n",
    "        lstm_model=lstm_model,\n",
    "        fractal_layers=fractal_layers,\n",
    "        rolling_window=rolling_window,\n",
    "        num_runs=num_runs,\n",
    "        max_iterations=max_iterations,\n",
    "        learning_rate=learning_rate,\n",
    "        fractal_regressive_coeff=fractal_regressive_coeff,\n",
    "        time_steps=time_steps,\n",
    "        predict_next=predict_next\n",
    "    )\n",
    "\n",
    "# =============================================================================\n",
    "# Entry Point\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bf059c-2b6e-4466-8776-f271ae799aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de9d45-d3a6-49f5-910a-12c87a21aaf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
