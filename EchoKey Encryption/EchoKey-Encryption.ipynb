{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c4011a-45ad-42a5-b217-d22b07ca4585",
   "metadata": {},
   "source": [
    "# EchoKey Encryption System: Detailed Overview\n",
    "\n",
    "The **EchoKey** encryption system is a sophisticated and robust implementation designed to leverage a unified mathematical framework for securing data. This detailed explanation bridges the theoretical principles of EchoKey with its practical Python implementation, elucidating how each component contributes to the system's overall functionality and security.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [System Architecture](#system-architecture)\n",
    "3. [Core Components](#core-components)\n",
    "    - [Configurable Variables](#configurable-variables)\n",
    "    - [Logging Configuration](#logging-configuration)\n",
    "    - [Seed Management](#seed-management)\n",
    "    - [Key Classes](#key-classes)\n",
    "        - [RollingWindow](#rollingwindow)\n",
    "        - [SynergyCalculator](#synergycalculator)\n",
    "        - [FractalGenerator](#fractalgenerator)\n",
    "        - [MultidimensionalState](#multidimensionalstate)\n",
    "        - [StateEvolver](#stateevolver)\n",
    "        - [KeystreamScrambler](#keystreamscrambler)\n",
    "        - [EchoKeyEncryption](#echokeyencryption)\n",
    "    - [Numba-Optimized Functions](#numba-optimized-functions)\n",
    "    - [Flip Map Mechanism](#flip-map-mechanism)\n",
    "    - [User Interface](#user-interface)\n",
    "4. [Encryption and Decryption Workflow](#encryption-and-decryption-workflow)\n",
    "    - [Encryption Process](#encryption-process)\n",
    "    - [Decryption Process](#decryption-process)\n",
    "5. [Performance Enhancements](#performance-enhancements)\n",
    "6. [Security Considerations](#security-considerations)\n",
    "7. [Conclusion](#conclusion)\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**EchoKey** is an advanced encryption system that embodies a comprehensive mathematical framework aimed at analyzing, controlling, and optimizing complex systems. By integrating principles from quantum mechanics, fractal geometry, recursion theory, synergy analysis, outlier management, and a multidimensional base-10 system, EchoKey offers a multifaceted approach to data encryption. This system ensures high entropy and randomness in the encrypted output, making it resilient against various cryptographic attacks.\n",
    "\n",
    "---\n",
    "\n",
    "## System Architecture\n",
    "\n",
    "The EchoKey system is architected to seamlessly integrate theoretical concepts with practical implementation. The core architecture comprises configurable settings, logging mechanisms, seed management, key classes that embody EchoKey principles, optimized computational functions, and a user-friendly interface for interaction.\n",
    "\n",
    "*Figure 1: High-level architecture of the EchoKey encryption system.*\n",
    "\n",
    "---\n",
    "\n",
    "## Core Components\n",
    "\n",
    "### Configurable Variables\n",
    "\n",
    "At the heart of EchoKey lies a set of configurable variables that dictate the system's behavior. These variables allow for flexibility and scalability, enabling the system to adapt to various encryption needs.\n",
    "\n",
    "```python\n",
    "# File Settings\n",
    "SEED_FILE = 'random_seed.txt'\n",
    "ZERO_DATA_FILE = 'zero_data.bin'\n",
    "TEST_DATA_FILE = 'test_data.bin'\n",
    "TEST_KEY_FILE = 'test_keys.bin'\n",
    "\n",
    "# General Settings\n",
    "WINDOW_SIZE = 8\n",
    "BATCH_SIZE = 102400\n",
    "DEBUG_MODE = False\n",
    "\n",
    "# Encryption Parameters\n",
    "PARAMS_ALPHA_INITIAL = 0.009\n",
    "PARAMS_BETA_INITIAL = 0.002\n",
    "PARAMS_OMEGA_INITIAL = 0.006\n",
    "\n",
    "# Numba Processing Parameters\n",
    "CHUNK_SIZE = 102400\n",
    "\n",
    "# Log File Settings\n",
    "DEBUG_LOG_DIR = 'logs'\n",
    "\n",
    "# EchoKey Framework Parameters\n",
    "SYNERGY_DIMENSIONS = 3\n",
    "KAPPA_MATRIX_SEED = 42\n",
    "FRACTAL_LEVELS = 5\n",
    "FRACTAL_BASE_CONSTANT = 0.4\n",
    "MULTIDIMENSIONAL_DIMENSIONS = 3\n",
    "OUTLIER_THRESHOLD = 0.1\n",
    "OUTLIER_WEIGHT = 1.0\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- **File Settings:** Define filenames for storing the seed, zero data, test data, and encrypted keys.\n",
    "- **General Settings:** Control the size of rolling windows, batch processing size, and debug mode status.\n",
    "- **Encryption Parameters:** Initial values for parameters influencing the encryption algorithm.\n",
    "- **Numba Processing Parameters:** Optimize batch processing using Numba's JIT compilation.\n",
    "- **Log File Settings:** Directory for storing debug logs.\n",
    "- **EchoKey Framework Parameters:** Define dimensions and constants for synergy calculations, fractal generation, and outlier management.\n",
    "\n",
    "---\n",
    "\n",
    "### Logging Configuration\n",
    "\n",
    "Robust logging is essential for monitoring the system's operations and facilitating debugging. The `configure_logging` function sets up logging handlers based on the debug mode.\n",
    "\n",
    "```python\n",
    "def configure_logging(debug: bool):\n",
    "    logger = logging.getLogger()\n",
    "    logger.handlers = []  # Clear existing handlers\n",
    "\n",
    "    log_level = logging.DEBUG if debug else logging.INFO\n",
    "    logger.setLevel(log_level)\n",
    "\n",
    "    # Console handler\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(log_level)\n",
    "    console_formatter = logging.Formatter('[%(asctime)s] [%(levelname)s] %(message)s')\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "    if debug:\n",
    "        if not os.path.exists(DEBUG_LOG_DIR):\n",
    "            os.makedirs(DEBUG_LOG_DIR)\n",
    "        \n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        debug_log_path = os.path.join(DEBUG_LOG_DIR, f'encryption_debug_{timestamp}.log')\n",
    "\n",
    "        # File handler\n",
    "        file_handler = logging.FileHandler(debug_log_path)\n",
    "        file_handler.setLevel(logging.DEBUG)\n",
    "        file_formatter = logging.Formatter('[%(asctime)s] [%(levelname)s] %(message)s')\n",
    "        file_handler.setFormatter(file_formatter)\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "        logging.debug(f\"Debug mode enabled. Logs are being saved to '{debug_log_path}'.\")\n",
    "```\n",
    "\n",
    "**Features:**\n",
    "\n",
    "- **Dynamic Logging Levels:** Switch between `DEBUG` and `INFO` levels based on the `DEBUG_MODE`.\n",
    "- **Dual Handlers:** Log messages are directed to both the console and a file (if debug mode is enabled).\n",
    "- **Timestamped Logs:** File logs are timestamped to prevent overwriting and ensure chronological tracking.\n",
    "\n",
    "---\n",
    "\n",
    "### Seed Management\n",
    "\n",
    "The seed is a fundamental component ensuring the randomness and security of the encryption process. The `get_seed_from_file` function manages seed retrieval and generation.\n",
    "\n",
    "```python\n",
    "def get_seed_from_file(filename: str) -> int:\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            seed_str = f.read().strip()\n",
    "        if not seed_str:\n",
    "            logging.warning(f\"Seed file '{filename}' is empty. Generating a new seed.\")\n",
    "            seed_str = ''.join([str(secrets.randbelow(10)) for _ in range(5000)])  # Generates a 5000-digit seed\n",
    "            with open(filename, 'w') as f:\n",
    "                f.write(seed_str)\n",
    "            logging.info(f\"Generated new seed and saved to '{filename}'.\")\n",
    "    else:\n",
    "        seed_str = ''.join([str(secrets.randbelow(10)) for _ in range(5000)])  # Generates a 5000-digit seed\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(seed_str)\n",
    "        logging.info(f\"Generated new seed and saved to '{filename}'.\")\n",
    "\n",
    "    try:\n",
    "        seed_int = int(seed_str)\n",
    "    except ValueError:\n",
    "        logging.error(f\"Seed file '{filename}' contains non-integer characters. Regenerating seed.\")\n",
    "        seed_int = int(''.join([str(secrets.randbelow(10)) for _ in range(5000)]))\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(str(seed_int))\n",
    "        logging.info(f\"Regenerated a valid 5000-digit seed and saved to '{filename}'.\")\n",
    "\n",
    "    logging.debug(f\"Seed integer: {seed_int}\")\n",
    "    return seed_int\n",
    "```\n",
    "\n",
    "**Process:**\n",
    "\n",
    "1. **Seed Retrieval:** Attempts to read the seed from the specified file.\n",
    "2. **Seed Validation:** If the file is empty or contains non-integer characters, a new 5000-digit seed is generated using `secrets.randbelow` for cryptographic security.\n",
    "3. **Seed Conversion:** Converts the seed string to an integer, ensuring it's suitable for subsequent encryption operations.\n",
    "4. **Logging:** Detailed logs are maintained for each step, facilitating traceability and debugging.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Classes\n",
    "\n",
    "EchoKey's functionality is encapsulated within several classes, each responsible for specific aspects of the encryption and decryption processes.\n",
    "\n",
    "#### RollingWindow\n",
    "\n",
    "Manages a fixed-size window of data, essential for rolling calculations like synergy and oscillatory behaviors.\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class RollingWindow:\n",
    "    data: np.ndarray\n",
    "    size: int\n",
    "    index: int = 0\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.data is None or len(self.data) != self.size:\n",
    "            logging.error(f\"RollingWindow data not properly initialized. Expected size {self.size}, got {len(self.data)}.\")\n",
    "            self.data = np.zeros(self.size, dtype=np.float64)\n",
    "            logging.debug(f\"RollingWindow data reinitialized to zeros with size {self.size}.\")\n",
    "\n",
    "    def update(self, value: float):\n",
    "        if len(self.data) == 0:\n",
    "            logging.error(\"Attempting to update an empty RollingWindow.\")\n",
    "            raise IndexError(\"RollingWindow data is empty.\")\n",
    "        self.data[self.index % self.size] = value\n",
    "        self.index += 1\n",
    "        logging.debug(f\"RollingWindow updated: index={self.index}, value={value}, data={self.data}\")\n",
    "\n",
    "    def get_neighbors(self, n_neighbors: int = 8) -> np.ndarray:\n",
    "        if n_neighbors > self.size:\n",
    "            n_neighbors = self.size\n",
    "\n",
    "        start = (self.index - n_neighbors) % self.size\n",
    "        if start + n_neighbors <= self.size:\n",
    "            return self.data[start:start + n_neighbors]\n",
    "        else:\n",
    "            end = (start + n_neighbors) % self.size\n",
    "            return np.concatenate((self.data[start:], self.data[:end]))\n",
    "\n",
    "    def get_recent(self, n: int = None) -> np.ndarray:\n",
    "        if n is None or n > self.size:\n",
    "            n = self.size\n",
    "\n",
    "        start = (self.index - n) % self.size\n",
    "        if start + n <= self.size:\n",
    "            return self.data[start:start + n]\n",
    "        else:\n",
    "            end = (start + n) % self.size\n",
    "            return np.concatenate((self.data[start:], self.data[:end]))\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "- **Circular Buffer:** Implements a circular buffer to efficiently manage rolling data without the overhead of shifting elements.\n",
    "- **Data Retrieval:** Provides methods to fetch recent or neighbor elements, facilitating calculations like synergy.\n",
    "\n",
    "---\n",
    "\n",
    "#### SynergyCalculator\n",
    "\n",
    "Computes the synergy term \\( S(\\Psi) \\), capturing the emergent behaviors arising from interactions between system components.\n",
    "\n",
    "```python\n",
    "class SynergyCalculator:\n",
    "    def __init__(self, dimensions: int, kappa_matrix: np.ndarray, functions: List[Callable]):\n",
    "        self.dimensions = dimensions\n",
    "        self.kappa_matrix = kappa_matrix  # Interaction coefficients matrix\n",
    "        self.functions = functions        # List of functions f_i(Ψ_i)\n",
    "\n",
    "    def calculate_synergy(self, psi_states: List[np.ndarray], time_steps: np.ndarray) -> float:\n",
    "        synergy = 0.0\n",
    "        dt = np.diff(time_steps)\n",
    "        num_steps = len(time_steps) - 1\n",
    "\n",
    "        for idx in range(num_steps):\n",
    "            for i in range(self.dimensions):\n",
    "                for j in range(self.dimensions):\n",
    "                    if i != j:\n",
    "                        fi = self.functions[i](psi_states[i][idx])\n",
    "                        fj = self.functions[j](psi_states[j][idx])\n",
    "                        synergy += self.kappa_matrix[i, j] * fi * fj * dt[idx]\n",
    "\n",
    "        return synergy\n",
    "```\n",
    "\n",
    "**Components:**\n",
    "\n",
    "- **Dimensions:** Number of system components interacting synergistically.\n",
    "- **Kappa Matrix:** Defines the strength of interactions between each pair of components.\n",
    "- **Functions:** Represents individual contributions of each component to the synergy.\n",
    "\n",
    "**Functionality:**\n",
    "\n",
    "Calculates the integral of pairwise interactions over time, quantifying the overall synergy within the system.\n",
    "\n",
    "---\n",
    "\n",
    "#### FractalGenerator\n",
    "\n",
    "Generates fractal structures, introducing self-similarity and complexity into the encryption process.\n",
    "\n",
    "```python\n",
    "class FractalGenerator:\n",
    "    def __init__(self, levels: int, base_function: Callable[[float], float]):\n",
    "        self.levels = levels\n",
    "        self.base_function = base_function\n",
    "\n",
    "    def generate(self, x: float, level: int = None) -> float:\n",
    "        if level is None:\n",
    "            level = self.levels\n",
    "        if level == 0:\n",
    "            return x\n",
    "        return self.base_function(self.generate(x, level - 1))\n",
    "```\n",
    "\n",
    "**Features:**\n",
    "\n",
    "- **Recursion:** Utilizes recursive calls to build complex, self-similar structures characteristic of fractals.\n",
    "- **Base Function:** Defines the iterative transformation applied at each recursion level.\n",
    "\n",
    "**Usage:**\n",
    "\n",
    "Enhances the encryption algorithm by embedding fractal patterns, increasing unpredictability and resistance to pattern analysis.\n",
    "\n",
    "---\n",
    "\n",
    "#### MultidimensionalState\n",
    "\n",
    "Handles state representations in a multidimensional base-10 framework, enabling high-dimensional data manipulation.\n",
    "\n",
    "```python\n",
    "class MultidimensionalState:\n",
    "    def __init__(self, dimensions: int):\n",
    "        self.dimensions = dimensions\n",
    "        self.state_vector_size = 10 ** dimensions\n",
    "        self.state_vector = np.zeros(self.state_vector_size)\n",
    "\n",
    "    def transform_state(self, psi: np.ndarray) -> np.ndarray:\n",
    "        # Placeholder for an actual transformation\n",
    "        return psi\n",
    "```\n",
    "\n",
    "**Attributes:**\n",
    "\n",
    "- **Dimensions:** Number of dimensions in the base-10 system.\n",
    "- **State Vector:** Represents the system's state across multiple dimensions, facilitating complex data interactions.\n",
    "\n",
    "**Methods:**\n",
    "\n",
    "- **`transform_state`:** Placeholder for applying necessary transformations to the state vector, potentially integrating scaling, normalization, or other data processing techniques.\n",
    "\n",
    "---\n",
    "\n",
    "#### StateEvolver\n",
    "\n",
    "Evolves the system's state over time by integrating synergy, fractal generation, regression, and outlier management.\n",
    "\n",
    "```python\n",
    "class StateEvolver:\n",
    "    def __init__(self, synergy_calc: SynergyCalculator, fractal_gen: FractalGenerator,\n",
    "                 state_handler: MultidimensionalState, regression_coeffs: List[float],\n",
    "                 outlier_term: Callable[[float], float]):\n",
    "        self.synergy_calc = synergy_calc\n",
    "        self.fractal_gen = fractal_gen\n",
    "        self.state_handler = state_handler\n",
    "        self.regression_coeffs = regression_coeffs\n",
    "        self.outlier_term = outlier_term\n",
    "\n",
    "    def evolve_state(self, psi_states: List[np.ndarray], t: float, time_steps: np.ndarray) -> np.ndarray:\n",
    "        N = len(self.regression_coeffs)\n",
    "        min_length = min(len(arr) for arr in psi_states)\n",
    "        evolved_state = np.zeros(min_length)\n",
    "\n",
    "        for n in range(N):\n",
    "            C_n_t = self.compute_cyclic_function(n, t)\n",
    "            F_n_minus1 = self.fractal_gen.generate(C_n_t, level=n)\n",
    "            regression = np.exp(-self.regression_coeffs[n] * t)\n",
    "            # Combine with each psi_state\n",
    "            for psi in psi_states:\n",
    "                evolved_state += (F_n_minus1 * regression) * psi[:min_length]\n",
    "\n",
    "        # Add synergy term\n",
    "        S_psi = self.synergy_calc.calculate_synergy(psi_states, time_steps)\n",
    "        evolved_state += S_psi\n",
    "\n",
    "        # Add outlier term\n",
    "        O_t = self.outlier_term(t)\n",
    "        evolved_state += O_t\n",
    "\n",
    "        # Transform state\n",
    "        evolved_state = self.state_handler.transform_state(evolved_state)\n",
    "        return evolved_state\n",
    "\n",
    "    def compute_cyclic_function(self, n: int, t: float) -> float:\n",
    "        A_n = 1.0 / (n + 1)\n",
    "        omega_n = 2 * np.pi * (n + 1)\n",
    "        phi_n = 0\n",
    "        return A_n * np.sin(omega_n * t + phi_n)\n",
    "```\n",
    "\n",
    "**Responsibilities:**\n",
    "\n",
    "- **State Evolution:** Combines fractal generation, regression, and synergy to evolve the system's state dynamically.\n",
    "- **Cyclic Function Computation:** Introduces periodic behaviors based on cyclicity principles, essential for maintaining randomness and complexity.\n",
    "- **Outlier Integration:** Incorporates outliers to adaptively manage unexpected deviations, ensuring system resilience.\n",
    "\n",
    "---\n",
    "\n",
    "#### KeystreamScrambler\n",
    "\n",
    "Generates and manages the keystream used for scrambling and unscrambling data, leveraging HMAC-SHA256 for security.\n",
    "\n",
    "```python\n",
    "class KeystreamScrambler:\n",
    "    def __init__(self, seed: int, secret_key: bytes = None):\n",
    "        self.seed = seed\n",
    "        self.counter = 0\n",
    "        self.hash_func = hashlib.sha256\n",
    "        if secret_key is None:\n",
    "            self.secret_key = str(self.seed).encode()\n",
    "            logging.debug(f\"Initial Key (derived from seed): {self.secret_key.hex()}\")\n",
    "        else:\n",
    "            self.secret_key = secret_key\n",
    "            logging.debug(f\"Initial Key (provided secret key): {self.secret_key.hex()}\")\n",
    "\n",
    "    def generate_keystream_block(self) -> bytes:\n",
    "        data = f\"{self.seed}:{self.counter}\".encode()\n",
    "        hmac_obj = hmac.new(self.secret_key, data, self.hash_func)\n",
    "        keystream_block = hmac_obj.digest()\n",
    "        self.counter += 1\n",
    "        logging.debug(f\"Generated Keystream Block {self.counter}: {keystream_block.hex()}\")\n",
    "        return keystream_block\n",
    "\n",
    "    def generate_keystream(self, length: int) -> bytes:\n",
    "        keystream = bytearray()\n",
    "        while len(keystream) < length:\n",
    "            keystream.extend(self.generate_keystream_block())\n",
    "        return bytes(keystream[:length])\n",
    "\n",
    "    def scramble(self, data: bytes) -> bytes:\n",
    "        keystream = self.generate_keystream(len(data))\n",
    "        entropy_mask = hashlib.sha256(keystream).digest()\n",
    "        entropy_mask = entropy_mask * ((len(data) + 31) // 32)\n",
    "        entropy_mask = entropy_mask[:len(data)]\n",
    "        scrambled = bytes([b ^ k ^ m for b, k, m in zip(data, keystream, entropy_mask)])\n",
    "        logging.debug(f\"Scrambled Data: {scrambled.hex()}\")\n",
    "        return scrambled\n",
    "\n",
    "    def unscramble(self, data: bytes) -> bytes:\n",
    "        keystream = self.generate_keystream(len(data))\n",
    "        entropy_mask = hashlib.sha256(keystream).digest()\n",
    "        entropy_mask = entropy_mask * ((len(data) + 31) // 32)\n",
    "        entropy_mask = entropy_mask[:len(data)]\n",
    "        unscrambled = bytes([b ^ k ^ m for b, k, m in zip(data, keystream, entropy_mask)])\n",
    "        logging.debug(f\"Unscrambled Data: {unscrambled.hex()}\")\n",
    "        return unscrambled\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "- **Deterministic Keystream Generation:** Uses HMAC-SHA256 with a secret key and counter to generate a deterministic keystream.\n",
    "- **Scrambling and Unscrambling:** Applies XOR operations with the keystream and an entropy mask to scramble data. The process is reversible, ensuring data integrity during decryption.\n",
    "- **Security:** HMAC-based keystreams ensure cryptographic strength, making the system resistant to various attack vectors.\n",
    "\n",
    "---\n",
    "\n",
    "#### EchoKeyEncryption\n",
    "\n",
    "Serves as the central class integrating all components to perform encryption and decryption operations.\n",
    "\n",
    "```python\n",
    "class EchoKeyEncryption:\n",
    "    def __init__(self, seed: int = None, window_size: int = WINDOW_SIZE, batch_size: int = BATCH_SIZE,\n",
    "                 debug: bool = DEBUG_MODE, secret_key: bytes = None):\n",
    "        self.window_size = window_size\n",
    "        self.batch_size = batch_size\n",
    "        self.debug = debug\n",
    "\n",
    "        # Initialize rolling windows for synergy, oscillators, and acoustic parameters\n",
    "        self.synergy_window = RollingWindow(np.zeros(window_size, dtype=np.float64), window_size)\n",
    "        self.oscillator_x_window = RollingWindow(np.zeros(window_size, dtype=np.float64), window_size)\n",
    "        self.oscillator_y_window = RollingWindow(np.zeros(window_size, dtype=np.float64), window_size)\n",
    "        self.acoustic_window = RollingWindow(np.zeros(window_size, dtype=np.float64), window_size)\n",
    "\n",
    "        # Initialize encryption parameters\n",
    "        self.params_alpha = PARAMS_ALPHA_INITIAL\n",
    "        self.params_beta = PARAMS_BETA_INITIAL\n",
    "        self.params_omega = PARAMS_OMEGA_INITIAL\n",
    "\n",
    "        # Initialize seed without truncation\n",
    "        if seed is None:\n",
    "            seed = secrets.randbits(256)  # Generate a 256-bit seed\n",
    "            logging.debug(f\"No seed provided. Generated random seed: {seed}\")\n",
    "        self.seed = seed  # Retain the full 256-bit seed\n",
    "\n",
    "        # Initialize system state (state preparation)\n",
    "        self.init_system_state()\n",
    "        self.position = 0\n",
    "\n",
    "        # Initialize the KeystreamScrambler with the seed and secret key for robust scrambling\n",
    "        self.scrambler = KeystreamScrambler(seed=self.seed, secret_key=secret_key)\n",
    "\n",
    "        # Initialize a list to store encrypted keys\n",
    "        self.encrypted_keys: List[bytes] = []\n",
    "\n",
    "        # Generate the flip map and its inverse using the encryption seed\n",
    "        self.flip_map = generate_flip_map(self.seed)  # Multi-dimensional flip map\n",
    "        self.inverted_flip_map = invert_flip_map(self.flip_map)  # For decryption\n",
    "        logging.debug(f\"Flip Map: {self.flip_map}\")\n",
    "        logging.debug(f\"Inverted Flip Map: {self.inverted_flip_map}\")\n",
    "\n",
    "        # Initialize EchoKey components\n",
    "        dimensions = SYNERGY_DIMENSIONS\n",
    "        np.random.seed(KAPPA_MATRIX_SEED)\n",
    "        kappa_matrix = np.random.rand(dimensions, dimensions)\n",
    "        np.fill_diagonal(kappa_matrix, 0)\n",
    "        functions = [lambda x: x for _ in range(dimensions)]\n",
    "        self.synergy_calculator = SynergyCalculator(dimensions, kappa_matrix, functions)\n",
    "\n",
    "        base_function = lambda x: x ** 2 + FRACTAL_BASE_CONSTANT\n",
    "        self.fractal_generator = FractalGenerator(levels=FRACTAL_LEVELS, base_function=base_function)\n",
    "\n",
    "        self.state_handler = MultidimensionalState(MULTIDIMENSIONAL_DIMENSIONS)\n",
    "\n",
    "        regression_coeffs = [0.1 * (n + 1) for n in range(FRACTAL_LEVELS)]\n",
    "        self.outlier_term = lambda t: 0  # Placeholder for outlier term\n",
    "\n",
    "        self.state_evolver = StateEvolver(\n",
    "            synergy_calc=self.synergy_calculator,\n",
    "            fractal_gen=self.fractal_generator,\n",
    "            state_handler=self.state_handler,\n",
    "            regression_coeffs=regression_coeffs,\n",
    "            outlier_term=self.outlier_term\n",
    "        )\n",
    "```\n",
    "\n",
    "**Initialization Steps:**\n",
    "\n",
    "1. **Rolling Windows Setup:** Initializes rolling windows for synergy, oscillators, and acoustic parameters, maintaining recent states crucial for dynamic calculations.\n",
    "2. **Seed Handling:** Ensures a secure and comprehensive seed is used, enhancing the system's entropy.\n",
    "3. **Keystream Scrambler:** Integrates the `KeystreamScrambler` for data scrambling based on the seed and an optional secret key.\n",
    "4. **Flip Map Generation:** Creates a multi-dimensional flip map and its inverse to obfuscate data further.\n",
    "5. **EchoKey Components Integration:** Sets up the `SynergyCalculator`, `FractalGenerator`, `MultidimensionalState`, and `StateEvolver`, embedding EchoKey's foundational principles into the encryption process.\n",
    "\n",
    "**Core Methods:**\n",
    "\n",
    "- **`init_system_state`**: Populates rolling windows with entropy-based initial values to kickstart the encryption dynamics.\n",
    "- **`randomize_state_transitions`**: Updates rolling windows based on feedback, ensuring dynamic and adaptive state changes.\n",
    "- **`process`**: Handles data encryption or decryption in batches, utilizing Numba-optimized functions for performance.\n",
    "- **`encrypt` and `decrypt`**: High-level methods orchestrating the entire encryption and decryption workflows, including key management and data transformations.\n",
    "\n",
    "**Encryption Workflow:**\n",
    "\n",
    "1. **Data Flipping:** Applies the multi-dimensional flip map to the input data, adding an initial layer of obfuscation.\n",
    "2. **Scrambling:** Uses the `KeystreamScrambler` to XOR the flipped data with a keystream and apply an entropy mask.\n",
    "3. **Batch Processing:** Processes the scrambled data in batches, applying oscillatory transformations and synergy calculations.\n",
    "4. **Key Evolution:** Evolves the encryption key after each batch, ensuring that subsequent batches are encrypted with unique keys.\n",
    "5. **Final Output:** Returns the ciphertext along with a concatenated list of encrypted keys, essential for the decryption process.\n",
    "\n",
    "**Decryption Workflow:**\n",
    "\n",
    "1. **Key Retrieval:** Extracts encrypted keys from the provided key file.\n",
    "2. **Batch Processing:** Processes the ciphertext in batches, reversing the encryption transformations using the corresponding keys.\n",
    "3. **Unscrambling:** Reverses the entropy mask and XOR operations to retrieve the scrambled data.\n",
    "4. **Data Unflipping:** Applies the inverse flip map to restore the original plaintext data.\n",
    "\n",
    "---\n",
    "\n",
    "### Numba-Optimized Functions\n",
    "\n",
    "To enhance computational efficiency, particularly during batch processing, Numba's JIT compilation is employed to accelerate critical functions.\n",
    "\n",
    "#### calculate_synergy_numba\n",
    "\n",
    "```python\n",
    "@njit\n",
    "def calculate_synergy_numba(data_block: np.ndarray, osc_x_window: np.ndarray, osc_y_window: np.ndarray) -> float:\n",
    "    if data_block.size == 0:\n",
    "        return 1.0\n",
    "    alpha = data_block.mean()\n",
    "    beta = data_block.std() + 1e-10  # Avoid division by zero\n",
    "    gamma = np.mean(osc_x_window * osc_y_window)\n",
    "    return (alpha / beta) + gamma\n",
    "```\n",
    "\n",
    "**Functionality:**\n",
    "\n",
    "- **Synergy Calculation:** Computes a synergy score based on the mean and standard deviation of the data block and the interaction between oscillator windows.\n",
    "- **Performance:** Accelerated using Numba's `@njit` decorator for real-time encryption/decryption operations.\n",
    "\n",
    "#### process_batch_numba\n",
    "\n",
    "```python\n",
    "@njit\n",
    "def process_batch_numba(\n",
    "    data_block: np.ndarray,\n",
    "    synergy_window: np.ndarray,\n",
    "    osc_x_window: np.ndarray,\n",
    "    osc_y_window: np.ndarray,\n",
    "    acoustic_window: np.ndarray,\n",
    "    params_alpha: float,\n",
    "    params_beta: float,\n",
    "    params_omega: float,\n",
    "    position_start: int,\n",
    "    is_encrypt: bool\n",
    ") -> Tuple[np.ndarray, float, float, float, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    n = len(data_block)\n",
    "    processed = np.empty(n, dtype=np.uint8)\n",
    "    \n",
    "    # Pre-validate parameters\n",
    "    params_alpha = max(0.001, min(0.999, params_alpha))\n",
    "    params_beta = max(0.001, min(0.999, params_beta))\n",
    "    params_omega = max(0.001, min(0.999, params_omega))\n",
    "    \n",
    "    for i in range(n):\n",
    "        position = position_start + i\n",
    "        \n",
    "        # Calculate synergy with cross-dimensional oscillations\n",
    "        synergy = calculate_synergy_numba(synergy_window, osc_x_window, osc_y_window)\n",
    "        synergy = max(0.1, min(10.0, synergy))\n",
    "        \n",
    "        prev_osc_x = max(-1.0, min(1.0, osc_x_window[-1]))\n",
    "        prev_osc_y = max(-1.0, min(1.0, osc_y_window[-1]))\n",
    "        \n",
    "        # Enhanced oscillator updates using tensor transformations\n",
    "        new_osc_x_val = prev_osc_y - params_alpha * prev_osc_x + synergy * math.sin(params_beta * position)\n",
    "        new_osc_y_val = -params_beta * prev_osc_x - (prev_osc_y ** 3) + params_alpha * math.cos(params_omega * position)\n",
    "        \n",
    "        # Clamp oscillator values\n",
    "        new_osc_x_val = max(-1.0, min(1.0, new_osc_x_val))\n",
    "        new_osc_y_val = max(-1.0, min(1.0, new_osc_y_val))\n",
    "        \n",
    "        # Safe acoustic value calculation\n",
    "        new_acoustic_val = (acoustic_window[-1] * math.pi + position) % 1.0\n",
    "        \n",
    "        # Parameter updates with bounds, incorporating metric tensor dynamics\n",
    "        new_alpha = 0.09 + 0.1 * math.tanh(new_acoustic_val * synergy)  # tanh is bounded\n",
    "        new_beta = 0.01 + 0.1 * math.atan(new_acoustic_val * synergy) / (math.pi/2)  # normalize atan\n",
    "        new_omega = 1.0 + 0.1 * math.sin(new_acoustic_val * 2 * math.pi * synergy)\n",
    "        \n",
    "        # Clamp parameters\n",
    "        new_alpha = max(0.001, min(0.999, new_alpha))\n",
    "        new_beta = max(0.001, min(0.999, new_beta))\n",
    "        new_omega = max(0.001, min(0.999, new_omega))\n",
    "        \n",
    "        # Safe rotation value\n",
    "        rotate = max(1, min(7, int(synergy * 7) % 8))\n",
    "        \n",
    "        # Safe oscillator and acoustic values for byte operations\n",
    "        osc_val = int((new_osc_x_val + 1) * 127) & 0xFF\n",
    "        ac_val = int(new_acoustic_val * 255) & 0xFF\n",
    "        \n",
    "        byte = data_block[i]\n",
    "        \n",
    "        if is_encrypt:\n",
    "            # Step 1: XOR with oscillator value\n",
    "            transformed_byte = byte ^ osc_val\n",
    "            # Step 2: Add acoustic value\n",
    "            transformed_byte = (transformed_byte + ac_val) & 0xFF\n",
    "            # Step 3: Rotate left\n",
    "            transformed_byte = ((transformed_byte << rotate) | (transformed_byte >> (8 - rotate))) & 0xFF\n",
    "        else:\n",
    "            # Step 1: Rotate right\n",
    "            transformed_byte = ((byte >> rotate) | (byte << (8 - rotate))) & 0xFF\n",
    "            # Step 2: Subtract acoustic value\n",
    "            transformed_byte = (transformed_byte - ac_val) & 0xFF\n",
    "            # Step 3: XOR with oscillator value\n",
    "            transformed_byte = transformed_byte ^ osc_val\n",
    "        \n",
    "        processed[i] = transformed_byte\n",
    "        \n",
    "        # Update windows safely\n",
    "        synergy_window[-1] = float(transformed_byte if is_encrypt else byte) / 255.0\n",
    "        osc_x_window[-1] = new_osc_x_val\n",
    "        osc_y_window[-1] = new_osc_y_val\n",
    "        acoustic_window[-1] = new_acoustic_val\n",
    "        \n",
    "        # Update parameters\n",
    "        params_alpha = new_alpha\n",
    "        params_beta = new_beta\n",
    "        params_omega = new_omega\n",
    "    \n",
    "    return processed, params_alpha, params_beta, params_omega, synergy_window, osc_x_window, osc_y_window, acoustic_window\n",
    "```\n",
    "\n",
    "**Functionality:**\n",
    "\n",
    "- **Data Transformation:** Encrypts or decrypts data by applying a series of transformations based on oscillator values, synergy calculations, and parameter evolutions.\n",
    "- **Parameter Evolution:** Dynamically adjusts `alpha`, `beta`, and `omega` parameters to introduce non-linearity and adaptability.\n",
    "- **Window Updates:** Maintains and updates rolling windows for synergy and oscillatory behaviors.\n",
    "- **Performance:** Accelerated using Numba to handle large data batches efficiently.\n",
    "\n",
    "---\n",
    "\n",
    "### Flip Map Mechanism\n",
    "\n",
    "The flip map introduces an additional layer of data obfuscation by permuting byte values in a multidimensional manner.\n",
    "\n",
    "#### Generate Flip Map\n",
    "\n",
    "```python\n",
    "def generate_flip_map(seed: int) -> np.ndarray:\n",
    "    rng = np.random.default_rng(seed)  # Seed-based RNG\n",
    "    byte_values = np.arange(256, dtype=np.uint8)\n",
    "    flip_map = rng.permutation(byte_values).reshape(16, 16)\n",
    "    return flip_map\n",
    "```\n",
    "\n",
    "**Process:**\n",
    "\n",
    "1. **Random Permutation:** Generates a random permutation of byte values (0–255) using a seed-based random number generator.\n",
    "2. **Reshaping:** Organizes the permutation into a 16x16 matrix, enabling multidimensional access.\n",
    "\n",
    "#### Invert Flip Map\n",
    "\n",
    "```python\n",
    "def invert_flip_map(flip_map: np.ndarray) -> np.ndarray:\n",
    "    inverted_map = np.empty((16, 16), dtype=np.uint8)\n",
    "    flat_flip_map = flip_map.flatten()\n",
    "    indices = np.argsort(flat_flip_map)\n",
    "    inverted_flat_map = np.arange(256, dtype=np.uint8)[indices]\n",
    "    inverted_map = inverted_flat_map.reshape(16, 16)\n",
    "    return inverted_map\n",
    "```\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "- **Reversibility:** Creates an inverse flip map to accurately revert the flipping process during decryption.\n",
    "\n",
    "#### Randomized Character Flip\n",
    "\n",
    "```python\n",
    "def randomized_character_flip(data: bytes, flip_map: np.ndarray) -> bytes:\n",
    "    data_array = np.frombuffer(data, dtype=np.uint8)\n",
    "    high_nibbles = data_array >> 4\n",
    "    low_nibbles = data_array & 0x0F\n",
    "    flipped_array = flip_map[high_nibbles, low_nibbles]\n",
    "    return flipped_array.tobytes()\n",
    "```\n",
    "\n",
    "**Functionality:**\n",
    "\n",
    "- **Nibble Separation:** Splits each byte into high and low nibbles.\n",
    "- **Flip Map Application:** Uses the high and low nibbles as indices to retrieve the flipped byte from the flip map.\n",
    "- **Reconstruction:** Combines the flipped bytes back into a byte sequence.\n",
    "\n",
    "**Security Enhancement:**\n",
    "\n",
    "- **Obfuscation:** Makes pattern analysis more challenging by permuting byte values based on a predefined map.\n",
    "\n",
    "---\n",
    "\n",
    "### User Interface\n",
    "\n",
    "EchoKey offers a command-line interface (CLI) for user interaction, facilitating encryption, decryption, testing, and configuration.\n",
    "\n",
    "```python\n",
    "def display_menu():\n",
    "    menu = \"\"\"\n",
    "    === Encryption-Decryption System Menu ===\n",
    "    Please select an option:\n",
    "    1. Encrypt a File\n",
    "    2. Decrypt a File\n",
    "    3. Encrypt Text Input\n",
    "    4. Decrypt Text Input\n",
    "    5. Test Single Byte Encryption/Decryption\n",
    "    6. Generate Test Data\n",
    "    7. Exit\n",
    "    8. Toggle Debug Mode\n",
    "    \"\"\"\n",
    "    print(menu)\n",
    "\n",
    "def main_menu():\n",
    "    while True:\n",
    "        display_menu()\n",
    "        choice = input(\"Enter your choice (1-8): \").strip()\n",
    "\n",
    "        if choice == '1':\n",
    "            encrypt_file()\n",
    "        elif choice == '2':\n",
    "            decrypt_file()\n",
    "        elif choice == '3':\n",
    "            encrypt_text()\n",
    "        elif choice == '4':\n",
    "            decrypt_text()\n",
    "        elif choice == '5':\n",
    "            test_single_byte_menu()\n",
    "        elif choice == '6':\n",
    "            generate_test_data_menu()\n",
    "        elif choice == '7':\n",
    "            print(\"Exiting the program. Goodbye!\")\n",
    "            logging.info(\"Program exited by the user.\")\n",
    "            sys.exit(0)\n",
    "        elif choice == '8':\n",
    "            toggle_debug_mode()\n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter a number between 1 and 8.\")\n",
    "            logging.warning(f\"Invalid menu choice entered: {choice}\")\n",
    "```\n",
    "\n",
    "**Options:**\n",
    "\n",
    "1. **Encrypt a File:** Encrypts a user-specified file, saving both the ciphertext and encrypted keys.\n",
    "2. **Decrypt a File:** Decrypts a user-specified encrypted file using the provided encrypted keys.\n",
    "3. **Encrypt Text Input:** Encrypts text entered directly into the console.\n",
    "4. **Decrypt Text Input:** Decrypts hex-encoded encrypted text entered into the console.\n",
    "5. **Test Single Byte Encryption/Decryption:** Performs a test encryption and decryption on a single byte to verify system integrity.\n",
    "6. **Generate Test Data:** Creates large datasets for stress-testing the encryption system.\n",
    "7. **Exit:** Terminates the program.\n",
    "8. **Toggle Debug Mode:** Enables or disables debug mode, adjusting logging verbosity accordingly.\n",
    "\n",
    "**User Experience:**\n",
    "\n",
    "- **Interactive Prompts:** Guides users through file paths and input data.\n",
    "- **Progress Indicators:** Utilizes `tqdm` to display progress bars during lengthy operations like encryption and decryption.\n",
    "- **Feedback and Logging:** Provides real-time feedback and maintains detailed logs for monitoring and debugging.\n",
    "\n",
    "---\n",
    "\n",
    "## Encryption and Decryption Workflow\n",
    "\n",
    "### Encryption Process\n",
    "\n",
    "1. **Data Flipping:**\n",
    "    - The input data undergoes a flipping process using the flip map (`randomized_character_flip`), which permutes byte values to obfuscate patterns.\n",
    "\n",
    "2. **Scrambling:**\n",
    "    - The flipped data is scrambled using the `KeystreamScrambler`, which applies XOR operations with a deterministic keystream and an entropy mask derived from the keystream itself.\n",
    "\n",
    "3. **Batch Processing:**\n",
    "    - The scrambled data is processed in batches using the Numba-optimized `process_batch_numba` function. This involves applying oscillatory transformations, calculating synergy, and evolving encryption parameters (`alpha`, `beta`, `omega`).\n",
    "\n",
    "4. **Key Evolution:**\n",
    "    - After processing each batch, the encryption key evolves based on feedback from the processed data. This dynamic key evolution enhances security by ensuring that each batch is encrypted with a unique key.\n",
    "\n",
    "5. **Final Output:**\n",
    "    - The final ciphertext is produced alongside a concatenated list of encrypted keys. These keys are essential for the decryption process and are stored securely.\n",
    "\n",
    "### Decryption Process\n",
    "\n",
    "1. **Key Retrieval:**\n",
    "    - Decryption begins by extracting the encrypted keys from the provided key file, reconstructing the sequence of keys used during encryption.\n",
    "\n",
    "2. **Batch Processing:**\n",
    "    - The ciphertext is processed in batches, reversing the encryption transformations using the corresponding keys and the Numba-optimized `process_batch_numba` function.\n",
    "\n",
    "3. **Unscrambling:**\n",
    "    - The scrambled data is unscrambled by reversing the XOR operations and entropy masking, restoring the flipped data.\n",
    "\n",
    "4. **Data Unflipping:**\n",
    "    - The flipped data is then reverted to its original form using the inverse flip map (`invert_flip_map`), yielding the decrypted plaintext.\n",
    "\n",
    "5. **Integrity Verification:**\n",
    "    - The system verifies the integrity of the decrypted data, ensuring it matches the original input before encryption.\n",
    "\n",
    "---\n",
    "\n",
    "## Performance Enhancements\n",
    "\n",
    "EchoKey incorporates several performance optimizations to ensure efficient and scalable operations:\n",
    "\n",
    "1. **Numba Optimization:**\n",
    "    - Computationally intensive functions like synergy calculation and batch processing are accelerated using Numba's Just-In-Time (JIT) compilation, significantly reducing execution time.\n",
    "\n",
    "2. **Batch Processing:**\n",
    "    - Processing data in large batches (`BATCH_SIZE = 102400`) minimizes overhead and maximizes throughput, especially for large datasets.\n",
    "\n",
    "3. **Progress Monitoring:**\n",
    "    - Utilizes `tqdm` to display progress bars during encryption and decryption, providing real-time feedback on operation status.\n",
    "\n",
    "4. **Memory Monitoring:**\n",
    "    - The `log_memory_usage` function tracks memory usage before and after processing, aiding in performance tuning and ensuring resource efficiency.\n",
    "\n",
    "---\n",
    "\n",
    "## Security Considerations\n",
    "\n",
    "EchoKey is meticulously designed to provide high levels of security through multiple layers of transformation and dynamic key management:\n",
    "\n",
    "1. **High Entropy Seed:**\n",
    "    - Generates a 5000-digit seed using cryptographically secure methods (`secrets.randbelow`), ensuring robust initial randomness.\n",
    "\n",
    "2. **Keystream Scrambling:**\n",
    "    - Employs HMAC-SHA256 with a secret key to generate deterministic yet secure keystreams for data scrambling, preventing predictable patterns.\n",
    "\n",
    "3. **Dynamic Key Evolution:**\n",
    "    - Encryption keys evolve dynamically based on feedback from processed data, introducing non-linearity and making it exceedingly difficult for attackers to predict key sequences.\n",
    "\n",
    "4. **Multi-Dimensional Flip Map:**\n",
    "    - The flip map mechanism permutes byte values in a multi-dimensional manner, adding an extra layer of obfuscation and enhancing resistance against pattern analysis.\n",
    "\n",
    "5. **Synergy and Fractality:**\n",
    "    - Integrates synergy calculations and fractal generation to introduce complex, self-similar transformations that enhance encryption strength.\n",
    "\n",
    "6. **Outlier Management:**\n",
    "    - Incorporates mechanisms to handle outliers, ensuring the system remains resilient against unexpected or malicious data inputs.\n",
    "\n",
    "7. **Parameter Clamping and Validation:**\n",
    "    - Ensures encryption parameters (`alpha`, `beta`, `omega`) remain within safe bounds to prevent instability and potential vulnerabilities.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The **EchoKey** encryption system exemplifies a harmonious blend of theoretical rigor and practical implementation. By embedding foundational principles such as cyclicity, recursion, fractality, synergy, and outlier management within a multidimensional base-10 framework, EchoKey delivers a highly secure, efficient, and adaptable encryption solution. Its modular architecture, combined with performance optimizations and comprehensive logging, makes it a robust tool for safeguarding data across various applications.\n",
    "\n",
    "As EchoKey continues to evolve, future enhancements may include integrating machine learning algorithms for adaptive security, expanding the flip map mechanisms for greater obfuscation, and refining synergy calculations to capture more intricate system interactions. Continuous testing and validation, as exemplified by the included testing functions, ensure that EchoKey remains at the forefront of encryption technology.\n",
    "\n",
    "Feel free to explore and extend the EchoKey system, contributing to its ongoing development and excellence in data security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e15be-abd8-492c-9917-0459d231eae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, List, Tuple\n",
    "import secrets\n",
    "import sys\n",
    "from tqdm import tqdm  # For progress bar\n",
    "import logging\n",
    "from numba import njit\n",
    "import math\n",
    "import hmac\n",
    "import os\n",
    "import struct  # For packing and unpacking integers\n",
    "import time\n",
    "import hashlib\n",
    "import psutil  # For memory monitoring\n",
    "\n",
    "#=============================================================================#\n",
    "#                            Configurable Variables                           #\n",
    "#=============================================================================#\n",
    "\n",
    "# File Settings\n",
    "SEED_FILE = 'random_seed.txt'            # Filename for the seed\n",
    "ZERO_DATA_FILE = 'zero_data.bin'         # Filename for zero data\n",
    "TEST_DATA_FILE = 'test_data.bin'         # Filename for test data\n",
    "TEST_KEY_FILE = 'test_keys.bin'          # Filename for test keys\n",
    "\n",
    "# General Settings\n",
    "WINDOW_SIZE = 8          # Size of the rolling windows for better randomness\n",
    "BATCH_SIZE = 102400             # Increased size of each processing batch for better performance\n",
    "DEBUG_MODE = False          # Enable debug mode (Set to True for debugging)\n",
    "\n",
    "# Encryption Parameters\n",
    "PARAMS_ALPHA_INITIAL = 0.009   # Initial alpha parameter\n",
    "PARAMS_BETA_INITIAL = 0.002    # Initial beta parameter\n",
    "PARAMS_OMEGA_INITIAL = 0.006    # Initial omega parameter\n",
    "\n",
    "# Numba Processing Parameters\n",
    "CHUNK_SIZE = 102400           # Increased chunk size for processing in numba\n",
    "\n",
    "# Log File Settings\n",
    "DEBUG_LOG_DIR = 'logs'         # Directory to store debug logs\n",
    "\n",
    "# EchoKey Framework Parameters\n",
    "SYNERGY_DIMENSIONS = 3                # Number of dimensions/components in synergy calculation\n",
    "KAPPA_MATRIX_SEED = 42                # Seed for generating kappa interaction coefficients\n",
    "FRACTAL_LEVELS = 5                    # Levels of recursion in fractal generation\n",
    "FRACTAL_BASE_CONSTANT = 0.4           # Constant 'c' in the fractal base function\n",
    "MULTIDIMENSIONAL_DIMENSIONS = 3       # Number of dimensions in the base-10 framework\n",
    "OUTLIER_THRESHOLD = 0.1               # Threshold for detecting outliers\n",
    "OUTLIER_WEIGHT = 1.0                  # Weight/significance of detected outliers\n",
    "\n",
    "#=============================================================================#\n",
    "#                                End of Config                                #\n",
    "#=============================================================================#\n",
    "\n",
    "def configure_logging(debug: bool):\n",
    "    \"\"\"\n",
    "    Configures logging to output to console and optionally to a debug log file.\n",
    "\n",
    "    Args:\n",
    "        debug (bool): Flag to enable or disable debug mode.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger()\n",
    "    logger.handlers = []  # Clear existing handlers\n",
    "\n",
    "    log_level = logging.DEBUG if debug else logging.INFO\n",
    "    logger.setLevel(log_level)\n",
    "\n",
    "    # Console handler\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(log_level)\n",
    "    console_formatter = logging.Formatter('[%(asctime)s] [%(levelname)s] %(message)s')\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "    if debug:\n",
    "        # Ensure the debug log directory exists\n",
    "        if not os.path.exists(DEBUG_LOG_DIR):\n",
    "            os.makedirs(DEBUG_LOG_DIR)\n",
    "        \n",
    "        # Create a timestamped log filename to prevent overwriting\n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        debug_log_path = os.path.join(DEBUG_LOG_DIR, f'encryption_debug_{timestamp}.log')\n",
    "\n",
    "        # File handler\n",
    "        file_handler = logging.FileHandler(debug_log_path)\n",
    "        file_handler.setLevel(logging.DEBUG)\n",
    "        file_formatter = logging.Formatter('[%(asctime)s] [%(levelname)s] %(message)s')\n",
    "        file_handler.setFormatter(file_formatter)\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "        logging.debug(f\"Debug mode enabled. Logs are being saved to '{debug_log_path}'.\")\n",
    "\n",
    "def get_seed_from_file(filename: str) -> int:\n",
    "    \"\"\"\n",
    "    Reads the seed string from the specified file.\n",
    "    If the file does not exist or is empty, generates a new seed,\n",
    "    writes it to the file, and returns the seed as an integer.\n",
    "\n",
    "    This function acts as the system's initial state,\n",
    "    providing the foundational randomness required for the encryption process.\n",
    "    \"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            seed_str = f.read().strip()\n",
    "        if not seed_str:\n",
    "            logging.warning(f\"Seed file '{filename}' is empty. Generating a new seed.\")\n",
    "            seed_str = ''.join([str(secrets.randbelow(10)) for _ in range(5000)])  # Generates a 5000-digit seed\n",
    "            with open(filename, 'w') as f:\n",
    "                f.write(seed_str)\n",
    "            logging.info(f\"Generated new seed and saved to '{filename}'.\")\n",
    "    else:\n",
    "        # Generate a new seed string with 5000 digits\n",
    "        seed_str = ''.join([str(secrets.randbelow(10)) for _ in range(5000)])  # Generates a 5000-digit seed\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(seed_str)\n",
    "        logging.info(f\"Generated new seed and saved to '{filename}'.\")\n",
    "\n",
    "    # Convert the seed string directly to an integer without hashing\n",
    "    try:\n",
    "        seed_int = int(seed_str)\n",
    "    except ValueError:\n",
    "        logging.error(f\"Seed file '{filename}' contains non-integer characters. Regenerating seed.\")\n",
    "        seed_int = int(''.join([str(secrets.randbelow(10)) for _ in range(4000)]))\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(str(seed_int))\n",
    "        logging.info(f\"Regenerated a valid 5000-digit seed and saved to '{filename}'.\")\n",
    "\n",
    "    logging.debug(f\"Seed integer: {seed_int}\")\n",
    "    return seed_int\n",
    "\n",
    "# Define the log_function decorator\n",
    "def log_function(func):\n",
    "    \"\"\"\n",
    "    A decorator to log function entry, exit, and their arguments and results.\n",
    "    \"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        logging.debug(f\"Entering function: {func.__name__} with args: {args}, kwargs: {kwargs}\")\n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            logging.debug(f\"Exiting function: {func.__name__} with result: {result}\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Exception in function: {func.__name__} with error: {e}\")\n",
    "            raise\n",
    "    return wrapper\n",
    "\n",
    "# Configure logging based on the current DEBUG_MODE\n",
    "configure_logging(DEBUG_MODE)\n",
    "\n",
    "# Initialize SEED using the seed file\n",
    "SEED = get_seed_from_file(SEED_FILE)\n",
    "\n",
    "#=============================================================================#\n",
    "#                                   Classes                                   #\n",
    "#=============================================================================#\n",
    "\n",
    "@dataclass\n",
    "class RollingWindow:\n",
    "    \"\"\"Efficient rolling window using a fixed size.\"\"\"\n",
    "    data: np.ndarray  # Array to hold the rolling window data\n",
    "    size: int         # Maximum size of the window\n",
    "    index: int = 0    # Current position in the window (circular)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"Ensure the data array is properly initialized.\"\"\"\n",
    "        if self.data is None or len(self.data) != self.size:\n",
    "            logging.error(f\"RollingWindow data not properly initialized. Expected size {self.size}, got {len(self.data)}.\")\n",
    "            self.data = np.zeros(self.size, dtype=np.float64)\n",
    "            logging.debug(f\"RollingWindow data reinitialized to zeros with size {self.size}.\")\n",
    "\n",
    "    def update(self, value: float):\n",
    "        \"\"\"Updates the rolling window with a new value.\"\"\"\n",
    "        if len(self.data) == 0:\n",
    "            logging.error(\"Attempting to update an empty RollingWindow.\")\n",
    "            raise IndexError(\"RollingWindow data is empty.\")\n",
    "        self.data[self.index % self.size] = value\n",
    "        self.index += 1\n",
    "        logging.debug(f\"RollingWindow updated: index={self.index}, value={value}, data={self.data}\")\n",
    "\n",
    "    def get_neighbors(self, n_neighbors: int = 8) -> np.ndarray:\n",
    "        \"\"\"Retrieve the most recent `n_neighbors` elements, respecting the 8-neighbor limit.\"\"\"\n",
    "        if n_neighbors > self.size:\n",
    "            n_neighbors = self.size\n",
    "\n",
    "        start = (self.index - n_neighbors) % self.size\n",
    "        if start + n_neighbors <= self.size:\n",
    "            return self.data[start:start + n_neighbors]\n",
    "        else:\n",
    "            end = (start + n_neighbors) % self.size\n",
    "            return np.concatenate((self.data[start:], self.data[:end]))\n",
    "\n",
    "    def get_recent(self, n: int = None) -> np.ndarray:\n",
    "        \"\"\"Retrieve the most recent `n` elements from the rolling window.\"\"\"\n",
    "        if n is None or n > self.size:\n",
    "            n = self.size\n",
    "\n",
    "        start = (self.index - n) % self.size\n",
    "        if start + n <= self.size:\n",
    "            return self.data[start:start + n]\n",
    "        else:\n",
    "            end = (start + n) % self.size\n",
    "            return np.concatenate((self.data[start:], self.data[:end]))\n",
    "\n",
    "class SynergyCalculator:\n",
    "    \"\"\"Calculates the synergy term S(Ψ) in the EchoKey framework.\"\"\"\n",
    "\n",
    "    def __init__(self, dimensions: int, kappa_matrix: np.ndarray, functions: List[Callable]):\n",
    "        self.dimensions = dimensions\n",
    "        self.kappa_matrix = kappa_matrix  # Interaction coefficients matrix\n",
    "        self.functions = functions        # List of functions f_i(Ψ_i)\n",
    "\n",
    "    def calculate_synergy(self, psi_states: List[np.ndarray], time_steps: np.ndarray) -> float:\n",
    "        \"\"\"Calculates the synergy term S(Ψ) using numerical integration.\"\"\"\n",
    "        synergy = 0.0\n",
    "        dt = np.diff(time_steps)\n",
    "        num_steps = len(time_steps) - 1\n",
    "\n",
    "        for idx in range(num_steps):\n",
    "            for i in range(self.dimensions):\n",
    "                for j in range(self.dimensions):\n",
    "                    if i != j:\n",
    "                        fi = self.functions[i](psi_states[i][idx])\n",
    "                        fj = self.functions[j](psi_states[j][idx])\n",
    "                        synergy += self.kappa_matrix[i, j] * fi * fj * dt[idx]\n",
    "\n",
    "        return synergy\n",
    "\n",
    "class FractalGenerator:\n",
    "    \"\"\"Generates fractal structures by recursive application of a base function.\"\"\"\n",
    "\n",
    "    def __init__(self, levels: int, base_function: Callable[[float], float]):\n",
    "        self.levels = levels\n",
    "        self.base_function = base_function\n",
    "\n",
    "    def generate(self, x: float, level: int = None) -> float:\n",
    "        \"\"\"Recursively generates the fractal value at the specified level.\"\"\"\n",
    "        if level is None:\n",
    "            level = self.levels\n",
    "        if level == 0:\n",
    "            return x\n",
    "        return self.base_function(self.generate(x, level - 1))\n",
    "\n",
    "class MultidimensionalState:\n",
    "    \"\"\"Handles state representations in a multidimensional base-10 space.\"\"\"\n",
    "\n",
    "    def __init__(self, dimensions: int):\n",
    "        self.dimensions = dimensions\n",
    "        self.state_vector_size = 10 ** dimensions\n",
    "        self.state_vector = np.zeros(self.state_vector_size)\n",
    "\n",
    "    def transform_state(self, psi: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Transforms the state vector as needed by the system.\"\"\"\n",
    "        # Placeholder for an actual transformation\n",
    "        return psi\n",
    "\n",
    "class StateEvolver:\n",
    "    \"\"\"Evolves the system's state over time, integrating EchoKey components.\"\"\"\n",
    "\n",
    "    def __init__(self, synergy_calc: SynergyCalculator, fractal_gen: FractalGenerator,\n",
    "                 state_handler: MultidimensionalState, regression_coeffs: List[float],\n",
    "                 outlier_term: Callable[[float], float]):\n",
    "        self.synergy_calc = synergy_calc\n",
    "        self.fractal_gen = fractal_gen\n",
    "        self.state_handler = state_handler\n",
    "        self.regression_coeffs = regression_coeffs\n",
    "        self.outlier_term = outlier_term\n",
    "\n",
    "    def evolve_state(self, psi_states: List[np.ndarray], t: float, time_steps: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Computes the evolved state at time t.\"\"\"\n",
    "        N = len(self.regression_coeffs)\n",
    "        min_length = min(len(arr) for arr in psi_states)\n",
    "        evolved_state = np.zeros(min_length)\n",
    "\n",
    "        for n in range(N):\n",
    "            C_n_t = self.compute_cyclic_function(n, t)\n",
    "            F_n_minus1 = self.fractal_gen.generate(C_n_t, level=n)\n",
    "            regression = np.exp(-self.regression_coeffs[n] * t)\n",
    "            # Combine with each psi_state\n",
    "            for psi in psi_states:\n",
    "                evolved_state += (F_n_minus1 * regression) * psi[:min_length]\n",
    "\n",
    "        # Add synergy term\n",
    "        S_psi = self.synergy_calc.calculate_synergy(psi_states, time_steps)\n",
    "        evolved_state += S_psi\n",
    "\n",
    "        # Add outlier term\n",
    "        O_t = self.outlier_term(t)\n",
    "        evolved_state += O_t\n",
    "\n",
    "        # Transform state\n",
    "        evolved_state = self.state_handler.transform_state(evolved_state)\n",
    "        return evolved_state\n",
    "\n",
    "    def compute_cyclic_function(self, n: int, t: float) -> float:\n",
    "        \"\"\"Computes the cyclic function C_n(t).\"\"\"\n",
    "        A_n = 1.0 / (n + 1)\n",
    "        omega_n = 2 * np.pi * (n + 1)\n",
    "        phi_n = 0\n",
    "        return A_n * np.sin(omega_n * t + phi_n)\n",
    "\n",
    "def evolve_key(\n",
    "    current_key: bytes, feedback: bytes, alpha: float, beta: float, omega: float, position: int, layer: int\n",
    ") -> bytes:\n",
    "    \"\"\"\n",
    "    Evolves the encryption key based on feedback and parameters,\n",
    "    incorporating refraction-inspired transformations.\n",
    "    \"\"\"\n",
    "    # Convert feedback to numpy array\n",
    "    feedback_array = np.frombuffer(feedback, dtype=np.uint8)\n",
    "\n",
    "    # Normalize feedback to calculate refractive index\n",
    "    refractive_index = (feedback_array.mean() / 255.0) % 1.0  # Normalize to [0, 1]\n",
    "\n",
    "    # Evolve parameters using refraction-inspired transformations\n",
    "    new_alpha = alpha * math.sqrt(1 + refractive_index ** 2) + layer * 0.01\n",
    "    new_beta = beta / (1 + refractive_index) + layer * 0.02\n",
    "    new_omega = omega + math.sin(refractive_index * math.pi) * layer\n",
    "\n",
    "    # Use new parameters for entropy injection\n",
    "    oscillation_effect = (\n",
    "        math.sin(new_alpha * position) +\n",
    "        math.cos(new_beta * position) +\n",
    "        math.sin(new_omega * position)\n",
    "    )\n",
    "    entropy = int(oscillation_effect * (10 ** 6)) & 0xFFFFFFFF  # Scale and mod to fit into 4 bytes\n",
    "    entropy_bytes = struct.pack('>I', entropy)\n",
    "\n",
    "    # Combine with the current key and feedback\n",
    "    combined = current_key + feedback + entropy_bytes\n",
    "\n",
    "    # HMAC with SHA-256\n",
    "    hmac_obj = hmac.new(current_key, combined, hashlib.sha256)\n",
    "    new_key = hmac_obj.digest()[:32]  # Use the first 256 bits\n",
    "\n",
    "    logging.debug(f\"Layer {layer}: Refraction evolved key. Alpha: {new_alpha}, Beta: {new_beta}, Omega: {new_omega}\")\n",
    "    return new_key\n",
    "\n",
    "class KeystreamScrambler:\n",
    "    \"\"\"Generates and uses a keystream for scrambling and unscrambling data.\"\"\"\n",
    "\n",
    "    def __init__(self, seed: int, secret_key: bytes = None):\n",
    "        \"\"\"\n",
    "        Initializes the Keystream Scrambler with a seed and an optional secret key.\n",
    "\n",
    "        Args:\n",
    "            seed (int): The seed value to initialize the scrambler.\n",
    "            secret_key (bytes, optional): An optional secret key. Defaults to None.\n",
    "        \"\"\"\n",
    "        self.seed = seed\n",
    "        self.counter = 0\n",
    "        self.hash_func = hashlib.sha256\n",
    "        # Convert the large integer seed to bytes directly without hashing\n",
    "        if secret_key is None:\n",
    "            self.secret_key = str(self.seed).encode()  # Use the seed string as bytes\n",
    "            logging.debug(f\"Initial Key (derived from seed): {self.secret_key.hex()}\")\n",
    "        else:\n",
    "            self.secret_key = secret_key\n",
    "            logging.debug(f\"Initial Key (provided secret key): {self.secret_key.hex()}\")\n",
    "\n",
    "    def generate_keystream_block(self) -> bytes:\n",
    "        \"\"\"\n",
    "        Generates a keystream block using HMAC-SHA256 with the seed and counter.\n",
    "\n",
    "        Returns:\n",
    "            bytes: The generated keystream block.\n",
    "        \"\"\"\n",
    "        data = f\"{self.seed}:{self.counter}\".encode()\n",
    "        # Use HMAC with the raw seed bytes and current counter for deterministic keystream\n",
    "        hmac_obj = hmac.new(self.secret_key, data, self.hash_func)\n",
    "        keystream_block = hmac_obj.digest()\n",
    "        self.counter += 1\n",
    "        logging.debug(f\"Generated Keystream Block {self.counter}: {keystream_block.hex()}\")\n",
    "        return keystream_block\n",
    "\n",
    "    def generate_keystream(self, length: int) -> bytes:\n",
    "        \"\"\"\n",
    "        Generates a keystream of the specified length.\n",
    "\n",
    "        Args:\n",
    "            length (int): The desired length of the keystream.\n",
    "\n",
    "        Returns:\n",
    "            bytes: The generated keystream.\n",
    "        \"\"\"\n",
    "        keystream = bytearray()\n",
    "        while len(keystream) < length:\n",
    "            keystream.extend(self.generate_keystream_block())\n",
    "        return bytes(keystream[:length])\n",
    "\n",
    "    def scramble(self, data: bytes) -> bytes:\n",
    "        \"\"\"\n",
    "        Scrambles the data by XORing it with the keystream and simulating wave-function collapse.\n",
    "\n",
    "        Args:\n",
    "            data (bytes): The plaintext data to scramble.\n",
    "\n",
    "        Returns:\n",
    "            bytes: The scrambled data.\n",
    "        \"\"\"\n",
    "        keystream = self.generate_keystream(len(data))\n",
    "        # Simulate wave-function collapse by introducing an entropy-based mask\n",
    "        entropy_mask = hashlib.sha256(keystream).digest()\n",
    "        entropy_mask = entropy_mask * ((len(data) + 31) // 32)\n",
    "        entropy_mask = entropy_mask[:len(data)]\n",
    "        scrambled = bytes([b ^ k ^ m for b, k, m in zip(data, keystream, entropy_mask)])\n",
    "        logging.debug(f\"Scrambled Data: {scrambled.hex()}\")\n",
    "        return scrambled\n",
    "\n",
    "    def unscramble(self, data: bytes) -> bytes:\n",
    "        \"\"\"\n",
    "        Unscrambles the data by reversing the scrambling process.\n",
    "\n",
    "        Args:\n",
    "            data (bytes): The scrambled data to unscramble.\n",
    "\n",
    "        Returns:\n",
    "            bytes: The unscrambled plaintext data.\n",
    "        \"\"\"\n",
    "        keystream = self.generate_keystream(len(data))\n",
    "        entropy_mask = hashlib.sha256(keystream).digest()\n",
    "        entropy_mask = entropy_mask * ((len(data) + 31) // 32)\n",
    "        entropy_mask = entropy_mask[:len(data)]\n",
    "        unscrambled = bytes([b ^ k ^ m for b, k, m in zip(data, keystream, entropy_mask)])\n",
    "        logging.debug(f\"Unscrambled Data: {unscrambled.hex()}\")\n",
    "        return unscrambled\n",
    "\n",
    "@njit\n",
    "def calculate_synergy_numba(data_block: np.ndarray, osc_x_window: np.ndarray, osc_y_window: np.ndarray) -> float:\n",
    "    \"\"\"Calculate synergy using Numba for speed.\n",
    "\n",
    "    Synergy represents the interconnectedness of states, influencing \n",
    "    the system's evolution with cross-dimensional oscillations.\n",
    "    \"\"\"\n",
    "    if data_block.size == 0:\n",
    "        return 1.0\n",
    "    alpha = data_block.mean()\n",
    "    beta = data_block.std() + 1e-10  # Avoid division by zero\n",
    "    gamma = np.mean(osc_x_window * osc_y_window)\n",
    "    return (alpha / beta) + gamma\n",
    "\n",
    "@njit\n",
    "def process_batch_numba(\n",
    "    data_block: np.ndarray,\n",
    "    synergy_window: np.ndarray,\n",
    "    osc_x_window: np.ndarray,\n",
    "    osc_y_window: np.ndarray,\n",
    "    acoustic_window: np.ndarray,\n",
    "    params_alpha: float,\n",
    "    params_beta: float,\n",
    "    params_omega: float,\n",
    "    position_start: int,\n",
    "    is_encrypt: bool\n",
    ") -> Tuple[np.ndarray, float, float, float, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    n = len(data_block)\n",
    "    processed = np.empty(n, dtype=np.uint8)\n",
    "    \n",
    "    # Pre-validate parameters\n",
    "    params_alpha = max(0.001, min(0.999, params_alpha))\n",
    "    params_beta = max(0.001, min(0.999, params_beta))\n",
    "    params_omega = max(0.001, min(0.999, params_omega))\n",
    "    \n",
    "    for i in range(n):\n",
    "        position = position_start + i\n",
    "        \n",
    "        # Calculate synergy with cross-dimensional oscillations\n",
    "        synergy = calculate_synergy_numba(synergy_window, osc_x_window, osc_y_window)\n",
    "        synergy = max(0.1, min(10.0, synergy))\n",
    "        \n",
    "        prev_osc_x = max(-1.0, min(1.0, osc_x_window[-1]))\n",
    "        prev_osc_y = max(-1.0, min(1.0, osc_y_window[-1]))\n",
    "        \n",
    "        # Enhanced oscillator updates using tensor transformations\n",
    "        new_osc_x_val = prev_osc_y - params_alpha * prev_osc_x + synergy * math.sin(params_beta * position)\n",
    "        new_osc_y_val = -params_beta * prev_osc_x - (prev_osc_y ** 3) + params_alpha * math.cos(params_omega * position)\n",
    "        \n",
    "        # Clamp oscillator values\n",
    "        new_osc_x_val = max(-1.0, min(1.0, new_osc_x_val))\n",
    "        new_osc_y_val = max(-1.0, min(1.0, new_osc_y_val))\n",
    "        \n",
    "        # Safe acoustic value calculation\n",
    "        new_acoustic_val = (acoustic_window[-1] * math.pi + position) % 1.0\n",
    "        \n",
    "        # Parameter updates with bounds, incorporating metric tensor dynamics\n",
    "        new_alpha = 0.09 + 0.1 * math.tanh(new_acoustic_val * synergy)  # tanh is bounded\n",
    "        new_beta = 0.01 + 0.1 * math.atan(new_acoustic_val * synergy) / (math.pi/2)  # normalize atan\n",
    "        new_omega = 1.0 + 0.1 * math.sin(new_acoustic_val * 2 * math.pi * synergy)\n",
    "        \n",
    "        # Clamp parameters\n",
    "        new_alpha = max(0.001, min(0.999, new_alpha))\n",
    "        new_beta = max(0.001, min(0.999, new_beta))\n",
    "        new_omega = max(0.001, min(0.999, new_omega))\n",
    "        \n",
    "        # Safe rotation value\n",
    "        rotate = max(1, min(7, int(synergy * 7) % 8))\n",
    "        \n",
    "        # Safe oscillator and acoustic values for byte operations\n",
    "        osc_val = int((new_osc_x_val + 1) * 127) & 0xFF\n",
    "        ac_val = int(new_acoustic_val * 255) & 0xFF\n",
    "        \n",
    "        byte = data_block[i]\n",
    "        \n",
    "        if is_encrypt:\n",
    "            # Step 1: XOR with oscillator value\n",
    "            transformed_byte = byte ^ osc_val\n",
    "            # Step 2: Add acoustic value\n",
    "            transformed_byte = (transformed_byte + ac_val) & 0xFF\n",
    "            # Step 3: Rotate left\n",
    "            transformed_byte = ((transformed_byte << rotate) | (transformed_byte >> (8 - rotate))) & 0xFF\n",
    "        else:\n",
    "            # Step 1: Rotate right\n",
    "            transformed_byte = ((byte >> rotate) | (byte << (8 - rotate))) & 0xFF\n",
    "            # Step 2: Subtract acoustic value\n",
    "            transformed_byte = (transformed_byte - ac_val) & 0xFF\n",
    "            # Step 3: XOR with oscillator value\n",
    "            transformed_byte = transformed_byte ^ osc_val\n",
    "        \n",
    "        processed[i] = transformed_byte\n",
    "        \n",
    "        # Update windows safely\n",
    "        synergy_window[-1] = float(transformed_byte if is_encrypt else byte) / 255.0\n",
    "        osc_x_window[-1] = new_osc_x_val\n",
    "        osc_y_window[-1] = new_osc_y_val\n",
    "        acoustic_window[-1] = new_acoustic_val\n",
    "        \n",
    "        # Update parameters\n",
    "        params_alpha = new_alpha\n",
    "        params_beta = new_beta\n",
    "        params_omega = new_omega\n",
    "    \n",
    "    return processed, params_alpha, params_beta, params_omega, synergy_window, osc_x_window, osc_y_window, acoustic_window\n",
    "\n",
    "def process_with_layers(self, data: bytes, num_layers: int = 3):\n",
    "    processed_data = data\n",
    "    for layer in range(num_layers):\n",
    "        logging.debug(f\"Processing layer {layer}\")\n",
    "        \n",
    "        # Update cyclic parameters via refraction\n",
    "        self.params_alpha, self.params_beta, self.params_omega = self.evolve_cyclic_parameters(\n",
    "            self.params_alpha, self.params_beta, self.params_omega, layer\n",
    "        )\n",
    "\n",
    "        # Process data for the current layer\n",
    "        processed_data = self.process(processed_data, is_encrypt=True)\n",
    "        \n",
    "        # Randomize state transitions with refraction\n",
    "        feedback = processed_data[:32]  # Use a slice of the processed data\n",
    "        self.randomize_state_transitions(feedback)\n",
    "    return processed_data\n",
    "\n",
    "def evolve_cyclic_parameters(alpha: float, beta: float, omega: float, layer: int) -> Tuple[float, float, float]:\n",
    "    refractive_index = (alpha + beta + omega) % 1.0  # Example refractive index calculation\n",
    "\n",
    "    # Apply refraction-inspired transformations\n",
    "    new_alpha = alpha * math.sqrt(1 + refractive_index ** 2) + layer * 0.01\n",
    "    new_beta = beta / (1 + refractive_index) + layer * 0.02\n",
    "    new_omega = omega + math.sin(refractive_index * math.pi) * layer\n",
    "\n",
    "    logging.debug(f\"Layer {layer}: Alpha={new_alpha}, Beta={new_beta}, Omega={new_omega}\")\n",
    "    return new_alpha, new_beta, new_omega\n",
    "\n",
    "#=============================================================================#\n",
    "#                            Enhanced Flipping Mechanism                      #\n",
    "#=============================================================================#\n",
    "\n",
    "def generate_flip_map(seed: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates a multi-dimensional flip map for byte values (0–255) using the given seed.\n",
    "\n",
    "    Args:\n",
    "        seed (int): Seed for the random number generator.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A multi-dimensional array representing the flip map.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)  # Seed-based RNG\n",
    "    byte_values = np.arange(256, dtype=np.uint8)\n",
    "    flip_map = rng.permutation(byte_values).reshape(16, 16)\n",
    "    return flip_map\n",
    "\n",
    "def invert_flip_map(flip_map: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Inverts a multi-dimensional flip map to allow reversing the flipping process.\n",
    "\n",
    "    Args:\n",
    "        flip_map (np.ndarray): The original flip map.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The inverted flip map.\n",
    "    \"\"\"\n",
    "    inverted_map = np.empty((16, 16), dtype=np.uint8)\n",
    "    flat_flip_map = flip_map.flatten()\n",
    "    indices = np.argsort(flat_flip_map)\n",
    "    inverted_flat_map = np.arange(256, dtype=np.uint8)[indices]\n",
    "    inverted_map = inverted_flat_map.reshape(16, 16)\n",
    "    return inverted_map\n",
    "\n",
    "def randomized_character_flip(data: bytes, flip_map: np.ndarray) -> bytes:\n",
    "    \"\"\"\n",
    "    Flips characters in the input data using a multi-dimensional flip map.\n",
    "\n",
    "    Args:\n",
    "        data (bytes): The input data to flip.\n",
    "        flip_map (np.ndarray): The multi-dimensional flip map.\n",
    "\n",
    "    Returns:\n",
    "        bytes: The flipped data.\n",
    "    \"\"\"\n",
    "    data_array = np.frombuffer(data, dtype=np.uint8)\n",
    "    high_nibbles = data_array >> 4\n",
    "    low_nibbles = data_array & 0x0F\n",
    "    flipped_array = flip_map[high_nibbles, low_nibbles]\n",
    "    return flipped_array.tobytes()\n",
    "\n",
    "#=============================================================================#\n",
    "#                                End of Classes                               #\n",
    "#=============================================================================#\n",
    "\n",
    "class EchoKeyEncryption:\n",
    "    \"\"\"Encryption system integrating the EchoKey theoretical framework.\"\"\"\n",
    "\n",
    "    def __init__(self, seed: int = None, window_size: int = WINDOW_SIZE, batch_size: int = BATCH_SIZE,\n",
    "                 debug: bool = DEBUG_MODE, secret_key: bytes = None):\n",
    "        self.window_size = window_size\n",
    "        self.batch_size = batch_size\n",
    "        self.debug = debug\n",
    "\n",
    "        # Initialize rolling windows for synergy, oscillators, and acoustic parameters\n",
    "        self.synergy_window = RollingWindow(np.zeros(window_size, dtype=np.float64), window_size)\n",
    "        self.oscillator_x_window = RollingWindow(np.zeros(window_size, dtype=np.float64), window_size)\n",
    "        self.oscillator_y_window = RollingWindow(np.zeros(window_size, dtype=np.float64), window_size)\n",
    "        self.acoustic_window = RollingWindow(np.zeros(window_size, dtype=np.float64), window_size)\n",
    "\n",
    "        # Initialize encryption parameters\n",
    "        self.params_alpha = PARAMS_ALPHA_INITIAL\n",
    "        self.params_beta = PARAMS_BETA_INITIAL\n",
    "        self.params_omega = PARAMS_OMEGA_INITIAL\n",
    "\n",
    "        # Initialize seed without truncation\n",
    "        if seed is None:\n",
    "            seed = secrets.randbits(256)  # Generate a 256-bit seed\n",
    "            logging.debug(f\"No seed provided. Generated random seed: {seed}\")\n",
    "        self.seed = seed  # Retain the full 256-bit seed\n",
    "\n",
    "        # Initialize system state (state preparation)\n",
    "        self.init_system_state()\n",
    "        self.position = 0\n",
    "\n",
    "        # Initialize the KeystreamScrambler with the seed and secret key for robust scrambling\n",
    "        self.scrambler = KeystreamScrambler(seed=self.seed, secret_key=secret_key)\n",
    "\n",
    "        # Initialize a list to store encrypted keys\n",
    "        self.encrypted_keys: List[bytes] = []\n",
    "\n",
    "        # Generate the flip map and its inverse using the encryption seed\n",
    "        self.flip_map = generate_flip_map(self.seed)  # Multi-dimensional flip map\n",
    "        self.inverted_flip_map = invert_flip_map(self.flip_map)  # For decryption\n",
    "        logging.debug(f\"Flip Map: {self.flip_map}\")\n",
    "        logging.debug(f\"Inverted Flip Map: {self.inverted_flip_map}\")\n",
    "\n",
    "        # Initialize EchoKey components\n",
    "        dimensions = SYNERGY_DIMENSIONS\n",
    "        np.random.seed(KAPPA_MATRIX_SEED)\n",
    "        kappa_matrix = np.random.rand(dimensions, dimensions)\n",
    "        np.fill_diagonal(kappa_matrix, 0)\n",
    "        # Define simple identity functions for each dimension; replace with actual functions as needed\n",
    "        functions = [lambda x: x for _ in range(dimensions)]\n",
    "        self.synergy_calculator = SynergyCalculator(dimensions, kappa_matrix, functions)\n",
    "\n",
    "        base_function = lambda x: x ** 2 + FRACTAL_BASE_CONSTANT\n",
    "        self.fractal_generator = FractalGenerator(levels=FRACTAL_LEVELS, base_function=base_function)\n",
    "\n",
    "        self.state_handler = MultidimensionalState(MULTIDIMENSIONAL_DIMENSIONS)\n",
    "\n",
    "        regression_coeffs = [0.1 * (n + 1) for n in range(FRACTAL_LEVELS)]\n",
    "        # Define an outlier term; replace with actual logic as needed\n",
    "        self.outlier_term = lambda t: 0  # Placeholder for outlier term\n",
    "\n",
    "        self.state_evolver = StateEvolver(\n",
    "            synergy_calc=self.synergy_calculator,\n",
    "            fractal_gen=self.fractal_generator,\n",
    "            state_handler=self.state_handler,\n",
    "            regression_coeffs=regression_coeffs,\n",
    "            outlier_term=self.outlier_term\n",
    "        )\n",
    "\n",
    "    @log_function\n",
    "    def init_system_state(self):\n",
    "        \"\"\"\n",
    "        Initializes the system's state buffers with entropy measures.\n",
    "        \"\"\"\n",
    "        rng = np.random.default_rng(self.seed)  # Use the full seed for RNG\n",
    "    \n",
    "        # Initialize with entropy-based values\n",
    "        entropy_values = rng.random(self.window_size)\n",
    "        for i in range(self.window_size):\n",
    "            value = entropy_values[i]\n",
    "            self.synergy_window.update(value)\n",
    "            self.oscillator_x_window.update(value * math.sin(value * math.pi))\n",
    "            self.oscillator_y_window.update(value * math.cos(value * math.pi))\n",
    "            self.acoustic_window.update(value % 1.0)\n",
    "    \n",
    "        # Ensure no NaN values\n",
    "        self.synergy_window.data = np.nan_to_num(self.synergy_window.data)\n",
    "        self.oscillator_x_window.data = np.nan_to_num(self.oscillator_x_window.data)\n",
    "        self.oscillator_y_window.data = np.nan_to_num(self.oscillator_y_window.data)\n",
    "        self.acoustic_window.data = np.nan_to_num(self.acoustic_window.data)\n",
    "    \n",
    "        logging.debug(\"System state initialized with entropy-based values.\")\n",
    "\n",
    "    @log_function\n",
    "    def display_seed(self):\n",
    "        \"\"\"Display the current seed in hexadecimal format.\"\"\"\n",
    "        seed_hex = hex(self.seed)[2:]  # Remove '0x' prefix\n",
    "        print(f\"Current Seed: {seed_hex}\")\n",
    "        logging.debug(f\"Current Seed: {seed_hex}\")\n",
    "                        \n",
    "    def randomize_state_transitions(self, feedback: bytes):\n",
    "        \"\"\"\n",
    "        Randomizes state transitions with improved numerical stability.\n",
    "        \"\"\"\n",
    "        if feedback is None or len(feedback) == 0:\n",
    "            feedback = b'\\x00' * 32\n",
    "        \n",
    "        try:\n",
    "            h = hmac.new(self.scrambler.secret_key, feedback, hashlib.sha256)\n",
    "            deterministic_bytes = h.digest()\n",
    "            \n",
    "            # Convert bytes to float values between 0 and 1 more safely\n",
    "            float_array = np.frombuffer(deterministic_bytes, dtype=np.uint32).astype(np.float64)\n",
    "            float_values = float_array / np.iinfo(np.uint32).max  # Normalize using maximum uint32 value\n",
    "            \n",
    "            # Ensure values are in valid range [0,1]\n",
    "            float_values = np.clip(float_values, 0.0, 1.0)\n",
    "            \n",
    "            # Replace any remaining invalid values\n",
    "            float_values = np.nan_to_num(float_values, nan=0.5, posinf=1.0, neginf=0.0)\n",
    "            \n",
    "            # Initialize rolling windows with validated values\n",
    "            for i in range(self.window_size):\n",
    "                value = float(float_values[i % len(float_values)])\n",
    "                # Add small epsilon to avoid exact zero values\n",
    "                value = max(1e-10, min(1.0 - 1e-10, value))\n",
    "                \n",
    "                self.synergy_window.update(value)\n",
    "                # Use safer trig calculations with bounded inputs\n",
    "                self.oscillator_x_window.update(value * np.sin(value * math.pi))\n",
    "                self.oscillator_y_window.update(value * np.cos(value * math.pi))\n",
    "                self.acoustic_window.update(value % 1.0)\n",
    "                \n",
    "                # Verify no invalid values\n",
    "                assert not np.isnan(self.synergy_window.data).any()\n",
    "                assert not np.isnan(self.oscillator_x_window.data).any()\n",
    "                assert not np.isnan(self.oscillator_y_window.data).any()\n",
    "                assert not np.isnan(self.acoustic_window.data).any()\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during state transition: {e}\")\n",
    "            # Fallback to safe default values\n",
    "            default_value = 0.5\n",
    "            for _ in range(self.window_size):\n",
    "                self.synergy_window.update(default_value)\n",
    "                self.oscillator_x_window.update(default_value * 0.7071)  # sin(π/4)\n",
    "                self.oscillator_y_window.update(default_value * 0.7071)  # cos(π/4)\n",
    "                self.acoustic_window.update(default_value)\n",
    "            logging.warning(\"Used fallback values for state transition\")\n",
    "\n",
    "    @log_function\n",
    "    def process(self, data: bytes, is_encrypt: bool, encrypted_keys: List[bytes] = None) -> bytes:\n",
    "        \"\"\"\n",
    "        Processes the data for encryption or decryption using the EchoKey framework.\n",
    "\n",
    "        Args:\n",
    "            data (bytes): The data to process.\n",
    "            is_encrypt (bool): Flag indicating encryption or decryption.\n",
    "            encrypted_keys (List[bytes], optional): List of encrypted keys for decryption.\n",
    "\n",
    "        Returns:\n",
    "            bytes: The processed data.\n",
    "        \"\"\"\n",
    "        log_memory_usage(\"Before processing\")\n",
    "        \n",
    "        if is_encrypt:\n",
    "            logging.debug(\"Encryption process started.\")\n",
    "            logging.debug(f\"Input data (hex): {data.hex()}\")\n",
    "            \n",
    "            # Step 1: Flip the input data using flip_map\n",
    "            flipped_data = randomized_character_flip(data, self.flip_map)\n",
    "            logging.debug(f\"Data after initial flipping (hex): {flipped_data.hex()}\")\n",
    "\n",
    "            # Step 2: Scramble the flipped data using KeystreamScrambler\n",
    "            scrambled_data = self.scrambler.scramble(flipped_data)\n",
    "            logging.debug(f\"Data after scrambling (hex): {scrambled_data.hex()}\")\n",
    "\n",
    "            data_to_process = scrambled_data\n",
    "        else:\n",
    "            logging.debug(\"Decryption process started.\")\n",
    "            logging.debug(f\"Input data (hex): {data.hex()}\")\n",
    "            data_to_process = data\n",
    "\n",
    "        # Assertions\n",
    "        if is_encrypt:\n",
    "            assert encrypted_keys is None, \"Encrypted keys should not be provided during encryption.\"\n",
    "        else:\n",
    "            assert encrypted_keys is not None, \"Encrypted keys must be provided for decryption.\"\n",
    "\n",
    "        processed = bytearray(len(data_to_process))\n",
    "        total_batches = (len(data_to_process) + self.batch_size - 1) // self.batch_size\n",
    "        batch_idx = 0  # To keep track of the current batch index\n",
    "\n",
    "        with tqdm(total=total_batches, desc=\"Encrypting\" if is_encrypt else \"Decrypting\", unit=\"batch\", dynamic_ncols=True) as pbar:\n",
    "            for idx in range(0, len(data_to_process), self.batch_size):\n",
    "                chunk = data_to_process[idx:idx + self.batch_size]\n",
    "                chunk_array = np.frombuffer(chunk, dtype=np.uint8)\n",
    "\n",
    "                logging.debug(f\"Processing batch {batch_idx}:\")\n",
    "                logging.debug(f\"Chunk before processing (hex): {chunk.hex()}\")\n",
    "\n",
    "                # Log the current state before processing\n",
    "                logging.debug(f\"Current params_alpha: {self.params_alpha}\")\n",
    "                logging.debug(f\"Current params_beta: {self.params_beta}\")\n",
    "                logging.debug(f\"Current params_omega: {self.params_omega}\")\n",
    "                logging.debug(f\"Current position: {self.position}\")\n",
    "\n",
    "                # Pass the entire rolling windows to the Numba function\n",
    "                synergy_window = self.synergy_window.data.copy()\n",
    "                osc_x_window = self.oscillator_x_window.data.copy()\n",
    "                osc_y_window = self.oscillator_y_window.data.copy()\n",
    "                acoustic_window = self.acoustic_window.data.copy()\n",
    "\n",
    "                processed_chunk, self.params_alpha, self.params_beta, self.params_omega, \\\n",
    "                synergy_window, osc_x_window, osc_y_window, acoustic_window = process_batch_numba(\n",
    "                    chunk_array,\n",
    "                    synergy_window,\n",
    "                    osc_x_window,\n",
    "                    osc_y_window,\n",
    "                    acoustic_window,\n",
    "                    self.params_alpha,\n",
    "                    self.params_beta,\n",
    "                    self.params_omega,\n",
    "                    self.position,\n",
    "                    is_encrypt\n",
    "                )\n",
    "\n",
    "                # Validate the size of returned arrays\n",
    "                if synergy_window.size != self.window_size or \\\n",
    "                   osc_x_window.size != self.window_size or \\\n",
    "                   osc_y_window.size != self.window_size or \\\n",
    "                   acoustic_window.size != self.window_size:\n",
    "                    logging.error(\"One of the rolling windows returned by process_batch_numba has an incorrect size.\")\n",
    "                    raise ValueError(\"Incorrect rolling window size returned by process_batch_numba.\")\n",
    "\n",
    "                logging.debug(f\"Processed chunk (hex): {processed_chunk.tobytes().hex()}\")\n",
    "\n",
    "                # Update the rolling windows with the new state from processing\n",
    "                self.synergy_window.data = synergy_window\n",
    "                self.oscillator_x_window.data = osc_x_window\n",
    "                self.oscillator_y_window.data = osc_y_window\n",
    "                self.acoustic_window.data = acoustic_window\n",
    "\n",
    "                # Insert the processed chunk back into the main data stream\n",
    "                processed[idx:idx + len(processed_chunk)] = processed_chunk.tobytes()\n",
    "\n",
    "                if is_encrypt:\n",
    "                    if batch_idx == 0:\n",
    "                        # During encryption, store the initial_key before any evolution\n",
    "                        self.encrypted_keys.append(self.scrambler.secret_key)\n",
    "                        logging.debug(f\"Batch {batch_idx}: Initial Key: {self.scrambler.secret_key.hex()}\")\n",
    "                    # During encryption, feedback is the encrypted chunk\n",
    "                    feedback = processed_chunk.tobytes()\n",
    "                    # Evolve the key using the feedback, oscillation parameters, and synergy\n",
    "                    self.scrambler.secret_key = evolve_key(\n",
    "                        self.scrambler.secret_key, \n",
    "                        feedback, \n",
    "                        self.params_alpha, \n",
    "                        self.params_beta, \n",
    "                        self.params_omega,\n",
    "                        synergy_window.mean(),\n",
    "                        self.position\n",
    "                    )\n",
    "                    # Store the evolved key\n",
    "                    encrypted_key = self.scrambler.secret_key\n",
    "                    self.encrypted_keys.append(encrypted_key)\n",
    "                    # Debugging: Log the evolved key\n",
    "                    logging.debug(f\"Batch {batch_idx}: Evolved Key: {encrypted_key.hex()}\")\n",
    "                    \n",
    "                    # **Enhancement: Randomize State Transitions**\n",
    "                    self.randomize_state_transitions(feedback)\n",
    "                else:\n",
    "                    if batch_idx < len(encrypted_keys):\n",
    "                        # During decryption, set the scrambler's key to the corresponding encrypted key\n",
    "                        current_key = encrypted_keys[batch_idx]\n",
    "                        self.scrambler.secret_key = current_key\n",
    "                        logging.debug(f\"Batch {batch_idx}: Set Key for Processing: {current_key.hex()}\")\n",
    "                        \n",
    "                        # **Enhancement: Randomize State Transitions During Decryption**\n",
    "                        self.randomize_state_transitions(current_key)\n",
    "                    else:\n",
    "                        logging.error(f\"Insufficient encrypted keys provided for batch {batch_idx}.\")\n",
    "                        raise ValueError(\"Insufficient encrypted keys provided for decryption.\")\n",
    "\n",
    "                self.position += len(processed_chunk)\n",
    "                batch_idx += 1\n",
    "                pbar.update(1)\n",
    "\n",
    "        processed_bytes = bytes(processed)\n",
    "        \n",
    "        if not is_encrypt:\n",
    "            logging.debug(\"Final decryption step:\")\n",
    "            logging.debug(f\"Before unscramble (hex): {processed_bytes.hex()}\")\n",
    "            # Step 2: Unscramble the data to retrieve the flipped data\n",
    "            unscrambled_data = self.scrambler.unscramble(processed_bytes)\n",
    "            logging.debug(f\"After unscrambling (hex): {unscrambled_data.hex()}\")\n",
    "\n",
    "            # Step 3: Reverse the flipping to get the original plaintext\n",
    "            flipped_back_data = randomized_character_flip(unscrambled_data, self.inverted_flip_map)\n",
    "            logging.debug(f\"Data after reversing flipping (hex): {flipped_back_data.hex()}\")\n",
    "\n",
    "            processed_bytes = flipped_back_data\n",
    "\n",
    "        log_memory_usage(\"After processing\")\n",
    "        return processed_bytes\n",
    "\n",
    "    @log_function\n",
    "    def encrypt(self, data: bytes) -> Tuple[bytes, bytes]:\n",
    "        \"\"\"\n",
    "        Encrypts the given data.\n",
    "\n",
    "        Args:\n",
    "            data (bytes): The plaintext data to encrypt.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[bytes, bytes]: A tuple containing the ciphertext and the concatenated encrypted keys with padding.\n",
    "        \"\"\"\n",
    "        ciphertext = self.process(data, is_encrypt=True)\n",
    "        # Concatenate all encrypted keys\n",
    "        actual_keys = b\"\".join(self.encrypted_keys)\n",
    "        num_keys = len(self.encrypted_keys)\n",
    "        initial_key_length = len(self.encrypted_keys[0])  # Length of the initial_key\n",
    "\n",
    "        # Create a 32-byte header\n",
    "        # First 4 bytes: number of keys (big endian)\n",
    "        # Next 4 bytes: length of the initial key (big endian)\n",
    "        # Next 24 bytes: random padding\n",
    "        header = struct.pack('>II', num_keys, initial_key_length) + secrets.token_bytes(24)\n",
    "\n",
    "        # Combine header and actual keys\n",
    "        encrypted_keys_combined = header + actual_keys\n",
    "\n",
    "        # Ensure the total length is a multiple of 32 bytes\n",
    "        if len(encrypted_keys_combined) % 32 != 0:\n",
    "            padding_length = 32 - (len(encrypted_keys_combined) % 32)\n",
    "            padding = secrets.token_bytes(padding_length)\n",
    "            encrypted_keys_combined += padding\n",
    "            logging.debug(f\"Appended {padding_length} bytes of random padding to encrypted_keys.\")\n",
    "\n",
    "        logging.debug(f\"Number of encrypted keys generated: {num_keys}\")\n",
    "        logging.debug(f\"Total encrypted keys length (bytes): {len(encrypted_keys_combined)}\")\n",
    "\n",
    "        return ciphertext, encrypted_keys_combined\n",
    "\n",
    "    @log_function\n",
    "    def decrypt(self, data: bytes, encrypted_keys: bytes) -> bytes:\n",
    "        \"\"\"\n",
    "        Decrypts the given data.\n",
    "\n",
    "        Args:\n",
    "            data (bytes): The ciphertext data to decrypt.\n",
    "            encrypted_keys (bytes): The concatenated encrypted keys with padding.\n",
    "\n",
    "        Returns:\n",
    "            bytes: The decrypted plaintext data.\n",
    "        \"\"\"\n",
    "        # Extract the header\n",
    "        header = encrypted_keys[:32]\n",
    "        num_keys, initial_key_length = struct.unpack('>II', header[:8])\n",
    "        logging.debug(f\"Number of keys extracted from header: {num_keys}\")\n",
    "        logging.debug(f\"Initial Key Length extracted from header: {initial_key_length}\")\n",
    "\n",
    "        # Extract the actual keys based on num_keys and initial_key_length\n",
    "        expected_length = 32 + (num_keys * 32)\n",
    "        if len(encrypted_keys) < 32 + initial_key_length + ((num_keys -1) *32):\n",
    "            raise ValueError(\"Encrypted keys data is shorter than expected based on the header information.\")\n",
    "\n",
    "        # Extract the initial_key and evolved_keys\n",
    "        initial_key = encrypted_keys[32:32 + initial_key_length]\n",
    "        evolved_keys = [encrypted_keys[i:i+32] for i in range(32 + initial_key_length, 32 + initial_key_length + ((num_keys -1)*32), 32)]\n",
    "        self.encrypted_keys = [initial_key] + evolved_keys  # Assign to the instance variable\n",
    "        logging.debug(f\"Initial Key: {initial_key.hex()}\")\n",
    "        logging.debug(f\"Number of evolved keys provided for decryption: {len(evolved_keys)}\")\n",
    "\n",
    "        # Any additional bytes are considered padding and are ignored\n",
    "\n",
    "        plaintext = self.process(data, is_encrypt=False, encrypted_keys=self.encrypted_keys)\n",
    "        return plaintext\n",
    "\n",
    "#=============================================================================#\n",
    "#                                    Tests                                   #\n",
    "#=============================================================================#\n",
    "\n",
    "# Configure logging (ensure this is defined appropriately in your actual code)\n",
    "def configure_logging(debug: bool):\n",
    "    log_level = logging.DEBUG if debug else logging.INFO\n",
    "    logging.basicConfig(\n",
    "        level=log_level,\n",
    "        format='[%(asctime)s] [%(levelname)s] %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(\"encryption.log\"),\n",
    "            logging.StreamHandler(sys.stdout)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "configure_logging(DEBUG_MODE)\n",
    "\n",
    "def log_memory_usage(stage: str):\n",
    "    \"\"\"Log current memory usage.\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "    logging.debug(f\"[Memory] {stage}: {memory:.2f} MB\")\n",
    "\n",
    "def test_single_byte():\n",
    "    \"\"\"Test encryption and decryption of a single byte with detailed debugging.\"\"\"\n",
    "    seed = SEED\n",
    "    # Set batch_size to 1 for single-byte test to avoid unnecessary iterations\n",
    "    encryptor = EchoKeyEncryption(seed=seed, window_size=WINDOW_SIZE, batch_size=1, debug=True, secret_key=None)\n",
    "    original = bytes([42])  # Single byte with value 42 (0x2A)\n",
    "    \n",
    "    logging.info(\"=== Encryption Process ===\")\n",
    "    logging.info(f\"Original byte: {original.hex()}\")\n",
    "    \n",
    "    encrypted, encrypted_keys = encryptor.encrypt(original)\n",
    "    logging.info(f\"Final encrypted: {encrypted.hex()}\")\n",
    "    logging.info(f\"Encrypted keys: {encrypted_keys.hex()}\")\n",
    "    logging.debug(f\"Encrypted keys length: {len(encrypted_keys)} bytes\")\n",
    "    \n",
    "    logging.info(\"\\n=== Decryption Process ===\")\n",
    "    decryptor = EchoKeyEncryption(seed=seed, window_size=WINDOW_SIZE, batch_size=1, debug=True, secret_key=None)\n",
    "    \n",
    "    decrypted = decryptor.decrypt(encrypted, encrypted_keys)\n",
    "    logging.info(f\"After main decryption: {decrypted.hex()}\")\n",
    "    \n",
    "    if original == decrypted:\n",
    "        print(\"Decryption successful!\")\n",
    "    else:\n",
    "        print(\"Decryption failed!\")\n",
    "        print(f\"Original: {original.hex()}\")\n",
    "        print(f\"Decrypted: {decrypted.hex()}\")\n",
    "        print(\"Differences in processing:\")\n",
    "        print(f\"Length original: {len(original)}, Length decrypted: {len(decrypted)}\")\n",
    "\n",
    "def generate_test_data(size: int = 100_000_000, batch_size: int = BATCH_SIZE, debug: bool = DEBUG_MODE, seed: int = SEED) -> Tuple[bytes, bytes]:\n",
    "    \"\"\"Generate test data using optimized encryption with a progress bar.\n",
    "\n",
    "    This function simulates the quantum system's evolution over a large dataset, \n",
    "    ensuring high entropy and randomness in the encrypted output.\n",
    "    \"\"\"\n",
    "    logging.info(\"Generating random data for encryption...\")\n",
    "\n",
    "    # Generate random data of the specified size\n",
    "    try:\n",
    "        data = os.urandom(size)  # Generates cryptographically secure random bytes\n",
    "        logging.info(f\"Generated {len(data)} bytes of random data.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to generate random data: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Initialize encryption system\n",
    "    encryptor = EchoKeyEncryption(seed=seed, window_size=WINDOW_SIZE, batch_size=batch_size, debug=debug, secret_key=None)\n",
    "    logging.info(\"Starting encryption of test data...\")\n",
    "\n",
    "    # Encrypt the data\n",
    "    try:\n",
    "        encrypted_data, encrypted_keys = encryptor.encrypt(data)\n",
    "        logging.info(f\"Encryption of test data completed. Encrypted data size: {len(encrypted_data)} bytes.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Encryption failed: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Save the encrypted data to the test data file\n",
    "    try:\n",
    "        with open(TEST_DATA_FILE, 'wb') as f:\n",
    "            f.write(encrypted_data)\n",
    "        logging.info(f\"Encrypted data saved to '{TEST_DATA_FILE}'.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error writing encrypted data to '{TEST_DATA_FILE}': {e}\")\n",
    "        raise\n",
    "\n",
    "    # Save the encrypted keys to the test key file\n",
    "    try:\n",
    "        with open(TEST_KEY_FILE, 'wb') as f:\n",
    "            f.write(encrypted_keys)\n",
    "        logging.info(f\"Encrypted keys saved to '{TEST_KEY_FILE}'.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error writing encrypted keys to '{TEST_KEY_FILE}': {e}\")\n",
    "        raise\n",
    "\n",
    "    return encrypted_data, encrypted_keys\n",
    "\n",
    "def generate_test_data_menu():\n",
    "    \"\"\"Generate test data by specifying size.\"\"\"\n",
    "    try:\n",
    "        size_input = input(\"Enter the size of test data to generate in bytes (e.g., 100000000 for ~100MB): \").strip()\n",
    "        size = int(size_input)\n",
    "        if size <= 0:\n",
    "            raise ValueError(\"Size must be a positive integer.\")\n",
    "    except ValueError as ve:\n",
    "        print(f\"Invalid size input: {ve}\")\n",
    "        logging.error(f\"Invalid size input provided for test data generation: {ve}\")\n",
    "        return\n",
    "\n",
    "    print(\"Generating test data...\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        # Call the generate_test_data function\n",
    "        test_data, test_keys = generate_test_data(size=size)\n",
    "        gen_time = time.time() - start_time\n",
    "        print(f\"Test data generated in {gen_time:.2f} seconds.\")\n",
    "        logging.info(f\"Test data of size {size} bytes generated in {gen_time:.2f} seconds.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Test data generation failed: {e}\")\n",
    "        logging.error(f\"Test data generation failed: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Test data saved to '{TEST_DATA_FILE}'.\")\n",
    "    print(f\"Encrypted keys saved to '{TEST_KEY_FILE}'.\")\n",
    "    logging.info(f\"Test data and keys saved successfully.\")\n",
    "\n",
    "def toggle_debug_mode():\n",
    "    \"\"\"Toggle the debug mode and reconfigure logging accordingly.\"\"\"\n",
    "    global DEBUG_MODE\n",
    "    current_status = \"ON\" if DEBUG_MODE else \"OFF\"\n",
    "    print(f\"Current Debug Mode: {current_status}\")\n",
    "    new_choice = input(\"Do you want to toggle the debug mode? (y/n): \").strip().lower()\n",
    "    \n",
    "    if new_choice == 'y':\n",
    "        DEBUG_MODE = not DEBUG_MODE\n",
    "        configure_logging(DEBUG_MODE)\n",
    "        new_status = \"enabled\" if DEBUG_MODE else \"disabled\"\n",
    "        print(f\"Debug mode has been {new_status}.\")\n",
    "    else:\n",
    "        print(\"Debug mode remains unchanged.\")\n",
    "        logging.debug(\"Debug mode toggle canceled by the user.\")\n",
    "\n",
    "def display_seed_menu():\n",
    "    \"\"\"Display the current seed.\"\"\"\n",
    "    encryptor = EchoKeyEncryption(seed=SEED, window_size=WINDOW_SIZE, batch_size=1, debug=DEBUG_MODE, secret_key=None)\n",
    "    encryptor.display_seed()\n",
    "\n",
    "def display_menu():\n",
    "    \"\"\"Display the options menu.\"\"\"\n",
    "    menu = \"\"\"\n",
    "    === Encryption-Decryption System Menu ===\n",
    "    Please select an option:\n",
    "    1. Encrypt a File\n",
    "    2. Decrypt a File\n",
    "    3. Encrypt Text Input\n",
    "    4. Decrypt Text Input\n",
    "    5. Test Single Byte Encryption/Decryption\n",
    "    6. Generate Test Data\n",
    "    7. Exit\n",
    "    8. Toggle Debug Mode\n",
    "    \"\"\"\n",
    "    print(menu)\n",
    "\n",
    "def main_menu():\n",
    "    \"\"\"Main menu loop to interact with the user.\"\"\"\n",
    "    while True:\n",
    "        display_menu()\n",
    "        choice = input(\"Enter your choice (1-8): \").strip()\n",
    "\n",
    "        if choice == '1':\n",
    "            encrypt_file()\n",
    "        elif choice == '2':\n",
    "            decrypt_file()\n",
    "        elif choice == '3':\n",
    "            encrypt_text()\n",
    "        elif choice == '4':\n",
    "            decrypt_text()\n",
    "        elif choice == '5':\n",
    "            test_single_byte_menu()\n",
    "        elif choice == '6':\n",
    "            generate_test_data_menu()\n",
    "        elif choice == '7':\n",
    "            print(\"Exiting the program. Goodbye!\")\n",
    "            logging.info(\"Program exited by the user.\")\n",
    "            sys.exit(0)\n",
    "        elif choice == '8':\n",
    "            toggle_debug_mode()\n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter a number between 1 and 8.\")\n",
    "            logging.warning(f\"Invalid menu choice entered: {choice}\")\n",
    "\n",
    "def encrypt_file():\n",
    "    \"\"\"Encrypt a file by specifying input and output file paths along with the key file.\"\"\"\n",
    "    input_path = input(\"Enter the path of the file to encrypt: \").strip()\n",
    "    output_path = input(\"Enter the path to save the encrypted file: \").strip()\n",
    "    key_path = input(\"Enter the path to save the encrypted keys: \").strip()\n",
    "\n",
    "    if not os.path.isfile(input_path):\n",
    "        print(f\"Error: The file '{input_path}' does not exist.\")\n",
    "        logging.error(f\"File '{input_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Read the input file\n",
    "    try:\n",
    "        with open(input_path, 'rb') as f:\n",
    "            data = f.read()\n",
    "        logging.info(f\"Read {len(data)} bytes from '{input_path}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file '{input_path}': {e}\")\n",
    "        logging.error(f\"Error reading file '{input_path}': {e}\")\n",
    "        return\n",
    "\n",
    "    # Initialize encryption system\n",
    "    encryptor = EchoKeyEncryption(seed=SEED, window_size=WINDOW_SIZE, batch_size=BATCH_SIZE, debug=DEBUG_MODE, secret_key=None)\n",
    "\n",
    "    # Encrypt the data\n",
    "    try:\n",
    "        encrypted_data, encrypted_keys = encryptor.encrypt(data)\n",
    "        logging.info(f\"Encryption completed. Encrypted data size: {len(encrypted_data)} bytes.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Encryption failed: {e}\")\n",
    "        logging.error(f\"Encryption failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # Write the encrypted data to the output file\n",
    "    try:\n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(encrypted_data)\n",
    "        logging.info(f\"Encrypted data written to '{output_path}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing encrypted data to '{output_path}': {e}\")\n",
    "        logging.error(f\"Error writing encrypted data to '{output_path}': {e}\")\n",
    "        return\n",
    "\n",
    "    # Write the encrypted keys to the key file\n",
    "    try:\n",
    "        with open(key_path, 'wb') as f:\n",
    "            f.write(encrypted_keys)\n",
    "        logging.info(f\"Encrypted keys written to '{key_path}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing encrypted keys to '{key_path}': {e}\")\n",
    "        logging.error(f\"Error writing encrypted keys to '{key_path}': {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Encryption successful!\\nEncrypted file saved at: {output_path}\\nEncrypted keys saved at: {key_path}\")\n",
    "\n",
    "def decrypt_file():\n",
    "    \"\"\"Decrypt a file by specifying encrypted file and key file paths along with the output file.\"\"\"\n",
    "    encrypted_path = input(\"Enter the path of the encrypted file to decrypt: \").strip()\n",
    "    key_path = input(\"Enter the path of the encrypted keys file: \").strip()\n",
    "    output_path = input(\"Enter the path to save the decrypted file: \").strip()\n",
    "\n",
    "    if not os.path.isfile(encrypted_path):\n",
    "        print(f\"Error: The encrypted file '{encrypted_path}' does not exist.\")\n",
    "        logging.error(f\"Encrypted file '{encrypted_path}' does not exist.\")\n",
    "        return\n",
    "    if not os.path.isfile(key_path):\n",
    "        print(f\"Error: The key file '{key_path}' does not exist.\")\n",
    "        logging.error(f\"Key file '{key_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Read the encrypted data\n",
    "    try:\n",
    "        with open(encrypted_path, 'rb') as f:\n",
    "            encrypted_data = f.read()\n",
    "        logging.info(f\"Read {len(encrypted_data)} bytes from '{encrypted_path}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading encrypted file '{encrypted_path}': {e}\")\n",
    "        logging.error(f\"Error reading encrypted file '{encrypted_path}': {e}\")\n",
    "        return\n",
    "\n",
    "    # Read the encrypted keys\n",
    "    try:\n",
    "        with open(key_path, 'rb') as f:\n",
    "            encrypted_keys = f.read()\n",
    "        logging.info(f\"Read {len(encrypted_keys)} bytes from '{key_path}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading key file '{key_path}': {e}\")\n",
    "        logging.error(f\"Error reading key file '{key_path}': {e}\")\n",
    "        return\n",
    "\n",
    "    # Initialize decryption system\n",
    "    decryptor = EchoKeyEncryption(seed=SEED, window_size=WINDOW_SIZE, batch_size=BATCH_SIZE, debug=DEBUG_MODE, secret_key=None)\n",
    "\n",
    "    # Decrypt the data\n",
    "    try:\n",
    "        decrypted_data = decryptor.decrypt(encrypted_data, encrypted_keys)\n",
    "        logging.info(f\"Decryption completed. Decrypted data size: {len(decrypted_data)} bytes.\")\n",
    "    except ValueError as ve:\n",
    "        print(f\"Decryption failed: {ve}\")\n",
    "        logging.error(f\"Decryption failed: {ve}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during decryption: {e}\")\n",
    "        logging.error(f\"Unexpected error during decryption: {e}\")\n",
    "        return\n",
    "\n",
    "    # Write the decrypted data to the output file\n",
    "    try:\n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(decrypted_data)\n",
    "        logging.info(f\"Decrypted data written to '{output_path}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing decrypted data to '{output_path}': {e}\")\n",
    "        logging.error(f\"Error writing decrypted data to '{output_path}': {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Decryption successful!\\nDecrypted file saved at: {output_path}\")\n",
    "\n",
    "def encrypt_text():\n",
    "    \"\"\"Encrypt a text input directly from the console.\"\"\"\n",
    "    text = input(\"Enter the text to encrypt: \").encode()\n",
    "\n",
    "    # Initialize encryption system\n",
    "    encryptor = EchoKeyEncryption(seed=SEED, window_size=WINDOW_SIZE, batch_size=BATCH_SIZE, debug=DEBUG_MODE, secret_key=None)\n",
    "\n",
    "    # Encrypt the text\n",
    "    try:\n",
    "        encrypted_data, encrypted_keys = encryptor.encrypt(text)\n",
    "        logging.info(f\"Encryption of text completed. Encrypted data size: {len(encrypted_data)} bytes.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Encryption failed: {e}\")\n",
    "        logging.error(f\"Encryption failed: {e}\")\n",
    "        return\n",
    "\n",
    "    # Display the results in hexadecimal format\n",
    "    print(f\"\\nEncrypted (hex): {encrypted_data.hex()}\")\n",
    "    print(f\"Encrypted Keys (hex): {encrypted_keys.hex()}\")\n",
    "    logging.debug(f\"Encrypted data (hex): {encrypted_data.hex()}\")\n",
    "    logging.debug(f\"Encrypted keys (hex): {encrypted_keys.hex()}\")\n",
    "\n",
    "def decrypt_text():\n",
    "    \"\"\"Decrypt a text input directly from the console.\"\"\"\n",
    "    encrypted_hex = input(\"Enter the encrypted data in hex: \").strip()\n",
    "    encrypted_keys_hex = input(\"Enter the encrypted keys in hex: \").strip()\n",
    "\n",
    "    try:\n",
    "        encrypted_data = bytes.fromhex(encrypted_hex)\n",
    "        encrypted_keys = bytes.fromhex(encrypted_keys_hex)\n",
    "    except ValueError:\n",
    "        print(\"Error: Invalid hexadecimal input.\")\n",
    "        logging.error(\"Invalid hexadecimal input provided for decryption.\")\n",
    "        return\n",
    "\n",
    "    # Initialize decryption system\n",
    "    decryptor = EchoKeyEncryption(seed=SEED, window_size=WINDOW_SIZE, batch_size=BATCH_SIZE, debug=DEBUG_MODE, secret_key=None)\n",
    "\n",
    "    # Decrypt the text\n",
    "    try:\n",
    "        decrypted_data = decryptor.decrypt(encrypted_data, encrypted_keys)\n",
    "        logging.info(f\"Decryption of text completed. Decrypted data size: {len(decrypted_data)} bytes.\")\n",
    "    except ValueError as ve:\n",
    "        print(f\"Decryption failed: {ve}\")\n",
    "        logging.error(f\"Decryption failed: {ve}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during decryption: {e}\")\n",
    "        logging.error(f\"Unexpected error during decryption: {e}\")\n",
    "        return\n",
    "\n",
    "    # Display decrypted data in hex and UTF-8\n",
    "    decrypted_hex = decrypted_data.hex()\n",
    "    print(f\"\\nDecrypted Data (hex): {decrypted_hex}\")\n",
    "    logging.debug(f\"Decrypted data (hex): {decrypted_hex}\")\n",
    "    print(f\"Decrypted Data (UTF-8): \", end=\"\")\n",
    "    try:\n",
    "        decrypted_text = decrypted_data.decode()\n",
    "        print(f\"{decrypted_text}\")\n",
    "        logging.debug(f\"Decrypted data (UTF-8): {decrypted_text}\")\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Invalid UTF-8 bytes.\")\n",
    "        logging.warning(\"Decrypted data contains invalid UTF-8 bytes.\")\n",
    "\n",
    "def test_single_byte_menu():\n",
    "    \"\"\"Run the single byte encryption and decryption test.\"\"\"\n",
    "    print(\"Running single byte test...\")\n",
    "    test_single_byte()\n",
    "    print(\"\\nSingle byte test completed.\\n\")\n",
    "\n",
    "#=============================================================================#\n",
    "#                                     Main                                    #\n",
    "#=============================================================================#\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_menu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e613a66-6b95-4b6e-baef-ba86bbab0c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
